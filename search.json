[{"title":"《深入理解JVM系列》之垃圾回收算法（二）","url":"/2020/03/23/JVM_2_垃圾回收算法/","content":"\n\n> Java虚拟机的内存区域中，程序计数器、虚拟机栈和本地方法栈三个区域是线程私有的，随线程生而生，随线程灭而灭；栈中的栈帧随着方法的进入和退出而进行入栈和出栈操作，每个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这三个区域的内存分配和回收都具有确定性。垃圾回收重点关注的是堆和方法区部分的内存。\n\n---\n\n## 垃圾标记算法\n\n常用的垃圾标记算法有：\n\n### 1.引用计数算法\n\n给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器都为0的对象就是不再被使用的，垃圾收集器将回收该对象使用的内存。\n\n引用计数算法实现简单，效率很高，微软的COM技术、ActionScript、Python等都使用了引用计数算法进行内存管理，但是引用计数算法对于对象之间相互循环引用问题难以解决，因此java并没有使用引用计数算法。\n\n\n### 2.根搜索算法：(可达性分析算法)\n\n通过一系列的名为“GC Root”的对象作为起点，从这些节点向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Root没有任何引用链相连时，则该对象不可达，该对象是不可使用的，垃圾收集器将回收其所占的内存。\n\n主流的商用程序语言C#、java和Lisp都使用根搜素算法进行内存管理。\n在java语言中，可作为GC Root的对象包括以下几种对象：\n\n1. Java虚拟机栈(栈帧中的本地变量表)中的引用的对象。\n2. 方法区中的类静态属性引用的对象。\n3. 方法区中的常量引用的对象。\n4. 本地方法栈中JNI本地方法的引用对象。\n\n> java方法区在Sun HotSpot虚拟机中被称为永久代，很多人认为该部分的内存是不用回收的，java虚拟机规范也没有对该部分内存的垃圾收集做规定，但是方法区中的废弃常量和无用的类还是需要回收以保证永久代不会发生内存溢出。\n\n判断废弃常量的方法：如果常量池中的某个常量没有被任何引用所引用，则该常量是废弃常量。\n判断无用的类必须同时满足下3个条件：\n\n1. 该类的所有实例都已经被回收，即java堆中不存在该类的实例对象。\n2. 加载该类的类加载器已经被回收。\n3. 该类所对应的java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射机制访问该类的方法。\n\n## 垃圾收集算法\n\nJava中常用的垃圾收集算法：\n\n### 1.标记-清除算法：\n\n最基础的垃圾收集算法，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成之后统一回收掉所有被标记的对象。\n标记-清除算法的缺点有两个：首先，效率问题，标记和清除效率都不高。其次，标记清除之后会产生大量的不连续的内存碎片，空间碎片太多会导致当程序需要为较大对象分配内存时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。\n\n### 2.复制算法：\n\n将可用内存按容量分成大小相等的两块，每次只使用其中一块，当这块内存使用完了，就将还存活的对象复制到另一块内存上去，然后把使用过的内存空间一次清理掉。这样使得每次都是对其中一块内存进行回收，内存分配时不用考虑内存碎片等复杂情况，只需要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。\n复制算法的缺点显而易见，可使用的内存降为原来一半。\n\n### 3.标记-整理算法：\n\n标记-整理算法在标记-清除算法基础上做了改进，标记阶段是相同的标记出所有需要回收的对象，在标记完成之后不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后移动过程中清理掉可回收的端边界以外的内存，这个过程叫做整理。\n标记-整理算法相比标记-清除算法的优点是内存被整理以后不会产生大量不连续内存碎片问题。\n复制算法在对象存活率高的情况下就要执行较多的复制操作，效率将会变低，而在对象存活率高的情况下使用标记-整理算法效率会大大提高。\n\n### 4.分代收集算法：\n\n根据内存中对象的存活周期不同，将内存划分为几块，java的虚拟机中一般把内存划分为新生代和年老代，当新创建对象时一般在新生代中分配内存空间，当新生代垃圾收集器回收几次之后仍然存活的对象会被移动到年老代内存中，当大对象在新生代中无法找到足够的连续内存时也直接在年老代中创建。\n\n现在的Java虚拟机就联合使用了**分代复制**、**标记-清除**和**标记-整理算法**，java虚拟机垃圾收集器关注的内存结构如下：\n\n<img src=\"/imgs/jvm_2_1.png\" width=\"70%\" />\n\n---\n\n堆内存被分成新生代和年老代两个部分，整个堆内存使用分代复制垃圾收集算法。\n\n#### 4.1 新生代\n\n新生代使用复制垃圾收集算法，研究表明，新生代中98%的对象是朝生夕死的短生命周期对象，所以不需要将新生代划分为容量大小相等的两部分内存，而是将新生代分为Eden区，Survivor from和Survivor to三部分，其占新生代内存容量默认比例分别为8：1：1，其中Survivor from和Survivor to总有一个区域是空白，只有Eden和其中一个Survivor总共90%的新生代容量用于为新创建的对象分配内存，只有10%的Survivor内存浪费，当新生代内存空间不足需要进行垃圾回收时，仍然存活的对象被复制到空白的Survivor内存区域中，随后Eden和Survivor空间被清理掉，两个Survivor区域是轮换的。\n\n新生代中98%情况下空白Survivor都可以存放垃圾回收时仍然存活的对象，2%的极端情况下，如果空白Survivor空间无法存放下仍然存活的对象时，使用内存分配担保机制，直接将新生代依然存活的对象复制到年老代内存中，同时对于创建大对象时，如果新生代中无足够的连续内存时，也直接在年老代中分配内存空间。\n\n> Java虚拟机对新生代的垃圾回收称为Minor GC，次数比较频繁，每次回收时间也比较短。使用java虚拟机-Xmn参数可以指定新生代内存大小。\n\n#### 4.2 年老代\n\n年老代中的对象一般都是长生命周期对象，对象的存活率比较高，因此在年老代中使用标记-整理、标记-清理垃圾回收算法。\n\nJava虚拟机对年老代的垃圾回收称为MajorGC/Full GC，次数相对比较少，每次回收的时间也比较长。\n\n当新生代中无足够空间为对象创建分配内存，年老代中内存回收也无法回收到足够的内存空间，并且新生代和年老代空间无法在扩展时，堆就会产生OutOfMemoryError异常。\n\n> java虚拟机-Xms参数可以指定最小内存大小，-Xmx参数可以指定最大内存大小，这两个参数分别减去Xmn参数指定的新生代内存大小，可以计算出年老代最小和最大内存容量。\n\n### 4.3 永久代\n\njava虚拟机内存中的方法区在Sun HotSpot虚拟机中被称为永久代，是被各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。永久代垃圾回收比较少，效率也比较低，但是也必须进行垃圾回收，否则会永久代内存不够用时仍然会抛出OutOfMemoryError异常。\n\n> 永久代也使用标记-整理算法进行垃圾回收，java虚拟机参数-XX:PermSize和-XX:MaxPermSize可以设置永久代的初始大小和最大容量。\n\n\n> PS:内存回收时候的细节：\n> \n>1. 枚举根节点（GC ROOT），其中需要停顿所有JAVA执行线程（stop-the-world）来保证一致性。\n>2. 为实现GC ROOT快速准确的枚举，需要OopMap的协助，为一种数据结构，用于存储对象内什么偏移量是什么类型的数据等。\n>3. 为了在特定的位置发生GC（因为不能每一条指令都进行GC，生成OopMap，这样空间成本会很高）因此需要设置安全点，条件为“长时间执行”的指令\n>4. 至于如何让GC发生时所有线程（除去JNI调用的线程）都在安全点停顿，可以使用抢先式中断和主动式中断。如今几乎没有虚拟机采用抢先式中断。\n>5. 对于那些不在执行的程序，如线程sleep或者blocked状态无法到安全点挂起，也不太可能让JVM等待，因此需要安全区域，即在一段引用关系不会变化的代码片段。这个区域在哪开始GC都安全，可看做是安全点的扩展。在线程要离开safe Region时，检测系统是否完成根节点枚举（或者是整个GC过程），是则继续执行，否则等待信号。\n\n\n","tags":["基础积累","深入理解JVM"]},{"title":"RPC服务的发展历程和对比分析","url":"/2020/03/20/RPC服务的发展历程和对比分析/","content":"\n## RPC服务的发展历程和对比分析\n\n网络编程术语：\n* 存根（stub），就像代理模式里的代理agent一样，负责连接时初始化网络通信上下文环境，使调用者和服务方的函数本地透明化。\n* 编码（encode），将请求报文封装到网络消息中的过程被称为编码(encode)\n* 解码（decode）,将请求报文从标准的网络格式转换成对应语言格式的过程被称作解码decode。\n> 在阅读netty的源码时经常能看到encode和decode的出现，基于这个概念能更好的理解netty的整个通信过程。\n\n---\n\n### 网络通信过程\n\n首先要了解网络编程接口的基础Socket套接字，它其实是一个通过ip+端口连接两端通信的一个句柄，socket由操作系统内核提供，为使用方向下屏蔽了传输协议（TCP、UDP）的具体细节。如图所示：\n\n<img src=\"/imgs/rpc_1.png\" width=\"60%\" />\n\n> ps :就像socket屏蔽了传输协议的通信细节一样，存根stub屏蔽了调用时的将请求/响应结果编码(encode)解码(decode)的细节。\n\n---\n\n### RPC服务的发展历程\n\n\n#### 面向过程的函数式RPC方式\n\nONC RPC是一个非常轻量级的RPC协议，可用于类POSIX的操作系统和POSIX的操作系统。\n\n其编译器用于生成客户端和服务端的存根函数，程序员需提供接口定义文件、函数声明、版本号、和唯一程序编号。\n\n然后要传输的入参会被封装到**XDR(外部数据表示)**这个数据结构中，来实现端到端的协议编码和解码。\n\n最后通过RPC封装的一个运行时库，实现必要的Sockect套接字来进行RPC调用。\n\n> 具体的ONC RPC定义文件就不具体介绍了，有兴趣的同学可以自行查询学习。\n\n整体的调用过程如图：\n\n<img src=\"/imgs/rpc_3.png\" width=\"60%\" />\n\n1. 启动服务器后，程序会创建一个socket套接字，并**调用svc_register函数来注册**程序号和版本号到port mapper中（端口映射器，独立的进程）。\n2. 启动客户端程序时，会根据调用名称、程序号版本号等**调用clnt_create从portmapper中获取远程系统的端口进行连接**。\n3. 客户端调用存根函数，存根函数使用端口号发送请求，并等待返回响应。\n4. 服务端收到消息，由存根函数调用并执行本地函数，返回给客户端。\n\n> 这里的portmapper的作用就是服务注册的功能。\n\n\n#### 面向对象的RPC方式\n\n> 主要代表是CORBA、和JAVA RMI，这里不详细说明了。\n\n#### SOA和微服务\n\n* Thrift\n如图\n\n<img src=\"/imgs/rpc_2.png\" width=\"60%\" />\n\n* ZeroCICe\n* gRPC，使用ProtoBuf作为序列化工具，用IDL作为跨平台协议语言。\n* Dubbo,主要提供三方面功能，远程服务调用；负载均衡和容错；服务注册和发现。\n","tags":["读书笔记","可伸缩服务架构+中间件"]},{"title":"分布式定时任务","url":"/2020/03/20/分布式定时任务/","content":"\n## 分布式定时任务\n\n> 书中的Linux的crontab、java的Timer以及ScheduledExecutor，不再说明，可自行了解。\n\n\n---\n\n### 一. Spring Scheduler\n\nSpring Scheduler的主要处理接口有：**TaskExecutor**、**TaskScheduler**、**Trigger**三个抽象接口\n* TaskExecutor是任务执行器，包含执行策略。\n* TaskScheduler是定时器，提供调度方法。\n* Trigger用于确定触发时间。\n\n#### 1.1 TaskExecutor接口\n\nTaskExecutor的实现类图如图所示：\n\n<img src=\"/imgs/sc_2.png\" width=\"100%\" />\n\n列重点介绍一下：\n\n1. **SimpleAsyncTaskExecutor**：重点是不重用线程，每个调用会开一个新线程，但是也会限制并发数，在任务数超出限制时阻塞。\n2. **SyncTaskExecutor**：同步执行任务\n3. **ConcurrentTaskExecutor**：是Executor对象的一个适配器，通常不会使用，如果正常的Execotor不能满足需求，则可以使用这个适配器做自定义。\n4. **SimpleTreadPoolTaskExecutor**：这个实现实际上是Quartz的一个子类，SimpleThreadPool监听Spring的生命周期回调。**可以兼容Quartz和非Quartz组件共享的线程池**\n5. **ThreadPoolTaskExecutor**：最常用的，配置ThreadPoolExecutor并保转成TaskExecutor。\n6. **WorkManagerTaskExecutor**：使用CommonJ WorkManager作为其后台实现，且WorkManager在Spring上下文中建立CommonJ引用的便利类。\n\n\n#### 1.2 TaskScheduler接口\n\n实现类图如图所示：\n\n\n<img src=\"/imgs/sc_1.png\" width=\"70%\" />\n\nTimerManagerTaskScheduler是使用CommonJ TimerManager实现的；\n\nThreadPoolTaskScheduler是使用线程池实现的;ThreadPoolTaskScheduler通过线程池是实现，并且它也实现了TaskExecutor接口。\n\n#### 1.3 Trigger接口\n\n实现类如如图所示：\n\n<img src=\"/imgs/sc_3.png\" width=\"70%\" />\n\nPeriodicTrigger是直接按照给定的实现间隔触发任务。\n\nCronTirgger是使用Cron表达式指定在什么时候执行任务。\n\n> 实现方面也不再赘述了，类似的博客用法已经有很多，大家也都很熟悉。\n\n\n### 二. Quartz\n\nQuartz的核心对象关系如下：\n\n<img src=\"/imgs/sc_4.png\" width=\"50%\" />\n\n* Job任务：表示一个工作，要执行的具体内容，只有一个execute方法。\n* JobDetail：任务的细节，表示一个具体的可执行的调度程序，Job是这个可执行的调度程序要执行的内容，而JobDetail还包含了任务调度的方案和策略。\n* Trigger：触发器，不详述\n* Scheduler：任务调度，代表一个调度容器，在一个调度容器中可以注册多个JobDetail和Triger，当Trigger和JobDetail组合时就可以被Scheduler调度了。\n\n> Quartz的这些对象在注册Spring的容器时都提供了**FactoryBean**的方式，将工厂bean注册进去，如SchedulerFactoryBean，JobDetailFactoryBean;\n\n>我们知道Spring以FactoryBean的方式来避免一些过于繁琐的初始化配置，而采用编码的方式来初始化一个Bean。\n\n\n### 三. 分布式定时任务\n\n分布式场景下的一个问题就是：**怎么让一个定时任务在一个触发时刻被仅有的一台服务器执行**。\n\n解决方案如下：\n\n1. 通过配置参数执行： 通过配置参数指定定时任务服务器执行指定的定时任务，缺点很明显，仍然存在单点问题。\n\n2. 通过全局锁来执行：节点获取到该任务的锁就可以开始执行任务，否则视为抢占失败，等待下一次扫描。\n\n\n#### 3.1 处理方式\n\n分布式定时任务的处理方式主要分两种：\n* 抢占式：进行任务资源的抢占，单个任务由单一节点独立完成。\n* 协同式：单个任务处理数据可以均分到多个JVM中进行处理。\n\n#### 3.2 分布式定时任务特点\n\n* 高可用，可伸缩，负载均衡，都是老生常谈。\n* 失效转移： 这个特点代表这**任务需要被持久化到磁盘中，而避免宕机带来的数据丢失风险**，同时还需要完善的**失败重试**，以及**任务追踪**和**报警策略**。\n\n> 一个高可用的分布式定时任务应用的设计需要考虑到上述所说的，**数据持久化、任务失败重试、任务追踪、故障报警策略**。\n\n\n\n#### 3.3 分布式锁的实现方式\n\n* 基于数据库的分布式锁\n* 基于redis的分布式锁\n* 基于zk的分布式锁\n>着重说一下zk的分布式锁，zk的内部是一个分层的文件系统目录树结构，规定在同一个目录下只能有一个唯一文件名。ZK的节点有如下集中类型：\n>* **永久节点，节点创建后，不会因为会话失效而丢失**\n>* **临时节点，与永久节点相反，客户端连接失效则删除该节点**\n\n在创建节点时可以通过配置选择是否在名称后加一个有序的数字后缀。\n\n除此之外，在创建节点时客户端还可以向该节点注册一个监视器，当节点状态改变时监视器能被触发，同时zk会向客户端发送一条通知（仅发一次）。\n\n因此zk上的分布式锁实现方式如下：\n1. 创建一个目录lock\n2. 线程A需要锁，则在lock下创建一个临时顺序节点。\n3. A判断自己是不是顺序最小的节点，如果是则获取锁。\n4. 否则向最小的节点设置一个监听器。\n5. 当最小节点释放后，触发监听器，A再次执行步骤3\n\n\n#### 3.4 Quartz的分布式定时任务\n\nQuartz支持基于数据库参数的分布式模型，可从官网上下载dbtable脚本来完成部署。\nQuartz的优点在于基于数据库可实现高可用；缺点是仅支持抢占式，同一个任务只有一个节点才能执行。\n\n> 一次定时任务被触发我们叫做**fire**；对应的如果定时任务未能按时执行则被叫做**misfire**\n库表字段如下：\n\n\n表名 | 描述\n---|---\nQRTZ_CALENDARS | 存储Quartz的Calendar信息\nQRTZ_CRON_TRIGGERS| 存储CronTrigger,包括Cron表达式时区信息\nQRTZ_FIRED_TRIGGERS| 存储与已触发的Trigger相关的状态信息，以及相关Job的执行信息\nQRTZ_PAUSED_TRIGGER_GRPS|存储已暂停的Trigger组信息\nQRTZ_SCHEDULER_STATE|存储少量的有关Scheduler的状态信息和Scheduler实例\nQRTZ_LOCKS|存储程序的悲观锁信息\nQRTZ_JOB_DETAILS|存储每一个已配置的Job的详细信息\nQRTZ_JOB_LISTENERS|存储有关已配置的JobListener的信息\nQRTZ_SIMPLE_TRIGGERS|存储简单的Trigger，包括重复次数、间隔及已触发的次数\nQRTZ_BLOG_TRIGGERS|Trigger作为Blob类型存储\nQRTZ_TRIGGER_LISTENERS|存储已配置的TriggerListener的信息\nQRTZ_TRIGGERS|存储已配置的Trigger的信息\n\n##### Quartz的使用tips\n* Quartz通过QUARTZ_LOCKS表来实现分布式锁，\n* Quartz对Trigger和Job的存储方式有：RAMJobStore和JobStoreSupport，内存和数据库两种存储方式\n* 定时任务misfire的原因和处理方法\n    * 系统因为重启或者宕机，错过fire时机\n    * Trigger被暂停导致错过fire时机\n    * 线程全部被占用，导致错过fire时机\n    * 有状态任务在触发时机时，上次任务还未结束\n> 对于misfire的情况，Quartz为Trigger定义了处理策略，主要有一下两种：\n> * MISFIRE_INSTRUCTION_FIRE_ONCE_NOW：针对misfired job马上执行一次\n> * MISFIRE_INSTRUCTION_DO_NOTHING：忽略misfired job，等待下次触发\n\n* Quartz中的job任务类型\n    * 无状态任务：任务之间独立。\n    * 有状态任务：任务之间存在关联。\n","tags":["读书笔记","可伸缩服务架构+中间件"]},{"title":"大数据利器之ElasticSearch","url":"/2020/03/20/大数据利器之ElasticSearch/","content":"\n## ElasticSearch\n\n在认识es之前，需要先对lucene有一个整体的认识\n### 一. lucene\n\n#### 1.1 核心模块\n\nlucene的核心模块如图所示：\n\n<img src=\"/imgs/es_1.png\" width=\"100%\" />\n\nanalysis: 词法分析，主要是做分词\nindex：创建索引\nstore：负责索引的读写等文件操作\nqueryParser：查询语句的语法分析器\nsearch：负责搜索索引\nsimilary：计算相关性打分和排序\n\n#### 1.2 核心概念\n\n* Term：最小分词单位\n\n* Term Dictionary：Term的集合，数据结构一般有数组、hash、以及**fst(finite-state transducer)**\n\n* 倒排表：存储结构\n\n* 段 segment：索引的最小独立存储单元。**段具有不变性，即一旦生成，不可写只能读。**\n\n#### 1.3 检索方式\n\n词的检索方式主要有，AND、OR、NOT。大致的查询方式就是先根据Term1查询倒排表，拿到文档集合1；在通过运算方式查询Term2，拿到文档集合2后再做归并。\n\n#### 1.4 分段存储\n\n分段存储是为了减轻写操作对索引变更的影响，同时分段采用不可变的设计，是为了提高读写性能，不用锁，也不用考虑多线程读写一致性问题。\n\n我们分别阐述一下各个操作是如何影响分段的：\n\n* 新增，在新的段中添加新的索引\n* 删除，由于**段不可变，所以在删除索引的时候通过添加一个标记文件.del，里面记录删除索引的id。在后面归并段的时候才会真正删除**。因此被删除的段是可以被查询到的，只是在做合并的时候才被过滤调。\n* 更新，由于不可变，所以更新操作需要删除旧的索引后新增新的索引。**因此在考虑为数据添加进索引的使用应该优先考虑数据的更新频率，太高的更新频率会导致大量空间浪费。**\n\n除此之外，我们还应该知道段是**被延迟写入的**，内容会先写到内存，然后通过时间间隔或者容量阈值来做异步刷新，生成提交点。\n> 在这里，**段被写在内存是只写非读的**，这点与在磁盘中是相反的。所以会存在准实时的延迟问题。\n**这里es通过事务日志来保证提交数据的安全**。\n\n#### 1.5 段合并策略\n\nlucene的段合并的策略是：**先将段按大小分组，对同组进行合并。**此外当段大于某一阈值时，便不在做合并。\n\n> 具体的段合并算法过程讲解，可以自行参考博客园[刘超绝先的博客](https://www.cnblogs.com/forfuture1978/archive/2010/03/06/1679501.html)\n\n#### 1.6 Lucene的打分机制\n\nlucene的相似度因子：\n* tf:某个term在文档中出现的次数\n\n\n$$tf = \\sqrt{termCountInDoc}$$\n\n\n* idf:表示的是整个文档集合中有这个词的文档数量越少越重要。\n$$idf = 1 + Log(\\frac{docCount}{docFreq+1})$$\n\n其中docCount为全量文档集合，docFreq指出现该term的文档数\n\n* length: 表示的是同等条件下，term所在文档的词量越小，相似度就应该越高。\n\n\n##### 1.6.1 基于向量空间模型\n\n核心思想是把文本信息映射到向量空间中，并通过计算向量之间的夹角来得出相似度。\n\n向量分为**查询语句向量**，和**文档向量**，向量指的是文档的权重，即文档内的term权重集，其中权重即tf x idf。\n\n> 关于具体的score相似度推导过程，可以自行查询。这里只列出结果\n\n$$score(q,d) = \\frac{1}{\\sqrt{\\sum_{t=0}^{t=f}{idf(t^2)}}} \\times \\sum({tf(tind) \\times idf(t^2) \\times \\frac{1}{\\sqrt{numOfTermsInFieldf}}})$$\n\n加入相似度打分公式后：\n\n$$score(q,d) = coord(q,d) \\times queryNorm(q) \\times \\sum{tf(tind) \\times idf(t^2) \\times t.getBoost() \\times norm(t,d)}$$\n\n其中\n\ncoord(q,d)= 文档d中包含查询词的个数/查询语句中包含t的个数\n\n$$queryNorm(q) = \\frac{1}{\\sqrt{q.getBoost()^2 \\times \\sum{(idf(t) \\times t.getBoost()^2)}}}$$\n\n$$norm(t,d) = d.getBoost() \\times lengthNorm(field) \\times \\prod_{fieldFInd}{f.getBoost()}$$\n\n##### 1.6.2 基于概率的模型\nBM25算法是根据BIM(Binary independent Model 二元独立模型)算法改进而来的，二元独立模型存在两个假设：\n* 一个词和文档的关系只有，相关和不相关两种关系\n* 文档里的词与词之间没有任何关联。\n\nBM25算法在BIM基础上添加了词的权重和两个经验参数，elaschsearch的默认算法已经由先前默认的向量空间模型变成了BM25。\n\nBM25的计算公式主要分两部分：\n\n{% math %}\nsocre(Q,d) = \\sum_{i}^{n}{W_i \\times R(q_i,d)}\n\n= \\sum_{i}^{n}{IDF(q_i) \\times \\frac{f_i \\times (k_1 + 1)}{f_i+k_1 \\times (1-b+b \\times \\frac{dl}{avgdl})}}\n{% endmath %}\n\n其中W是第词的权重，R(q,d)是每个词和文档的相关度值。\n\n这里的IDF值的计算方式与上述不太相同，但最后表示的含义都是一样的。\n\nf：值词在文档中出现的次数\n\ndl：表示文档的长度\n\navgdl：文档平均长度\n\nk1:调节因子，调整词频对得分的影响，默认1.2\n\nb:调节因子，调整字段长度对的得分的影响，默认0.75\n\n> 具体的公式同样不展示了，自行查询吧。\n\n## ElasticSearch\n\n### 一. 核心概念\n\n* Cluster集群：一个集群有多个节点\n* Node节点，服务单元\n* Shard分片，对索引做水平拆分，**分片在索引创建的时候就要确定，一旦确定就不能更改**。\n* Replicas副本，每个分片都有主分片以及可能的副本分片\n* Index索引：索引是集群内的唯一标识，类似于数据库\n* Tpye类别，索引内的逻辑分区，唯一标志。在es7.x后被移除。\n* Document文档，一条正向数据\n* Setting：对集群中索引的定义config\n* Mapping：类似数据库中表结构的信息，用于定义索引中Field字段的存储类型，分词方式等。es是能自动根据数据格式进行识别，但是也可以进行手动设置，**索引的mapping一旦创捷且存了数据就不可修改了**。\n* Analyzer：字段的分词定义，通常由tokenizer，几个Filter组成。默认的Analyzer则由标准的分词tokenizer和三个filter:StandardTokenFilter、LowerCaseTokenFilter、StopTokenFilter。\n\nES的节点分类如下：\n* 主节点masterNode:主节点负责创建、删除索引、分配分片、监控集群其他节点分配状态。配置node.master=true即可\n> 用户的请求可以发到任一节点，并由该节点进行分发和归并。并不需要es的主节点做转发。\n* 数据节点DataNode：负责存储数据即相关操作，如索引数据的增删改查聚合等。对性能要求较大。配置node.data=true即可\n* 客户端节点ClientNode：只负责请求分发归并，任意一个类型的节点都可以完成，单独增加是为了提高并发性。配置node.master=false;node.data=false即可\n* 部落节点TribeNode，用于协同多个集群，es7.0后移除\n* 协调节点CoordinatingNode：不是真正的节点，而是一种角色，集群中任何节点都可以当协调节点的角色，即负责处理分发和归并，无法配置。\n\n集群状态有三种：\n* Green绿色，主分片和副本分片都可正常工作。\n* Yellow黄色，主分片可用，副本分片存在不可用状态。\n* Red红色，至少一个主分片及全部副本分片不可用，此时查询请求可以返回部分结果，涉及该分片的写入请款将报错。\n\n### 二. 3C和脑裂\n\n#### 2.1 3C\n\n3C,即一致性(Consistency)、并发性(Concurrency)和共识性(Consensus)\n* 一致性： es的写一致性通过控制校验多数分片是否可写，分为:one主分片可用即可、All所有分片均需要可用、Quorun大多数分片可用即可；此外es保证读写一致性的方式是可以通过设置sync来使主分片和备份分片在写入时进行强同步。\n* 并发性：es通过乐观锁来控制主分片写入后同步各个备份分片的无序性的。\n* 共识性：es通过自研的zen discovery来实现共识算法，大致是以**Gossip的形式实现了单播**\n\n> 对于zen discovery ，有兴趣的读者可以自行查阅资料。\n\n#### 2.2 脑裂\n\n脑裂现象就是，由于可能存在主节点因为网络原因短暂失去通信，而选举产生了另一个新的主节点。多个主节点的情形。\n\n### 三. 事务日志\n\n事务日志主要是用来解决es的内存与磁盘写入存在准实时不一致的问题。当数据在内存中没有持久化到磁盘时如果出现意外情况，则会出现数据丢失。因此es添加了事务日志(Translog)来记录还没有持久化到磁盘之间的数据。\n\nes在写数据到内存的同时，会追加一份数据到事务日志当中。\n\n\n<img src=\"/imgs/es_4.png\" width=\"70%\" />\n\n如图:es写索引的过程经历几个步骤：\n1. es写入jvm内存中，同时追加数据到事务日志中。\n2. 触发refresh，将jvm内存写入文件缓冲区，生成一个新的段，并启用对该文件的读。同时清空jvm内存继续写数据（触发refresh的条件往往默认段刷新时间到阈值或者内存积压达到阈值）\n3. 触发fsync，先将jvm内存内数据写入文件缓冲区，清空内存，再将文件缓存区的段刷入硬盘。（触发刷盘操作往往是因为日志数据达到阈值或者刷盘时间达到阈值）\n4. 生成提交点。\n5. 清空事务日志。\n\n\n### 四. 集群中的写索引流程\n\nes的节点及分片例子如下图所示：\n\n\n<img src=\"/imgs/es_3.png\" width=\"70%\" />\n\n\n当es的写请求发出时，该请求会被发送到其中一个节点（协调节点），随后：\n1. 节点对写入的文档进行分片路由，确认将要写入那个分片pn中。\n2. 该节点将写入请求转发至pn主分片所在的节点中。\n3. pn主分片所在节点写入索引，如果成功，则异步/同步（视配置而定）请求其余副本分片执行写操作。\n4. 如果是同步分发副本分片，则等待副本分片均写入完成再返回协调节点写入成功的结果，协调节点返回写入请求结果。\n\n> 分片不可修改的原因就在于路由。\n\n\n### 五. 集群中的查询流程\n\n\n查询部分可以说是重点部分了\n\n查询部分可以分为根据routing id 查询和普通查询\n\n\n<img src=\"/imgs/es_2.png\" width=\"70%\" />\n\n#### 5.1 routing id查询\n\nrouting id查询主要是根据文档的主键_id来查询（通常都是docId）\n\n1. 请求打到某一个节点，则该节点成为协调节点。\n2. 该协调节点通过进行分片路由，找出对应分片（主分片或副本分片，视轮询而定）所在的节点，将请求转发过去。\n3. 该节点进行查询，并返回结果给协调节点，协调节点返回请求。\n\n##### 5.2 普通查询\n\n1. 请求达到某一个节点时，则该节点称为协调节点\n2. 该协调节点**创建一个from+size的优先队列**，然后将请求分发至其余各个分片中。\n3. 各个分片均进行查询，**得到对应的docId以及score，放入本地的from+size的优先队列中**。\n4. 各个分片返回队列中的**docId和score**到协调节点中，由协调节点做多个结果的归并，最后放入自己的优先队列中。\n5. 协调节点首先找到需要返回的**size条数据**，然后根据docId通过路由分发到对应的分片中进行查询，归并查询结果并返回。\n\n\n> 根据这种查询方式我们知道，我们应该尽量避免Deep Pagination（深翻），而应该采用scroll滚动。深翻中from数据越大导致浪费的查询资源就越多，性能下滑就越多。\n\n**scan扫描和scroll滚屏**\n\nscroll滚屏策略作为对深翻的一个补充,他的大致思路是对于分页查询的数据,一次性取回全量数据,并构建快照视图来进行查询.\n\nscan指的是查询方式,即查询的时候不对结果进行排序和评分,可以通过search_type=scan来设置\n\n### 六. 常用的es接口\n\n目前有一些开源软件对es提供的接口进行封装,可以方便的监控集群的状况.\n\nes提供了以下的接口:\n\n> 这里只提供可用于监控的一些接口.\n\n#### cat接口\n\n执行 curl -XGET localhost:9200/_cat 获取所有相关的_cat命令:\n```\n/_cat/aliases\n/_cat/aliases/{alias}\n/_cat/templates\n/_cat/health\n/_cat/nodes\n/_cat/allocation\n/_cat/count\n/_cat/count/{index}\n/_cat/indices\n/_cat/indices/{index}\n/_cat/recovery\n/_cat/recovery/{index}\n/_cat/pending_tasks\n/_cat/thread_pool\n/_cat/thread_pool/{thread_pools}/_cat/tasks\n/_cat/nodeattrs\n/_cat/master\n/_cat/snapshots/{repository}\n/_cat/segments\n/_cat/segments/{index}\n/_cat/fielddata\n/_cat/fielddata/{fields}\n/_cat/shards\n/_cat/shards/{index}\n/_cat/plugins\n/_cat/repositories\n```\n\n> 在上述接口后加入下列参数可以实现:\n> * v(verbose):使所有数据显示表头信息\n> * help:输出该命令可以显示的列\n> * h:可以指定返回的字段\n\n#### 查询集群的状态\n\n```\n/_cluster/health #查询集群健康状态;后加参数level=indices表示索引级状态;加参数level=shards表示分片粒度级状态\n/_cluster/state  #查询集群状态\n/_cluster/stats  #查看集群统计信息,返回包括索引个数,节点信息,分片信息,内存信息等\n/indexname/_stats # 查看索引的统计信息,包括查询次数,耗时,分片数,merge数,刷新次数等\n/_cluster/pending_tasks # 查询挂起的任务接口,返回集群中待执行的任务.\n```\n\n#### 查看节点的状态\n\n```\n/_nodes #查看节点信息\n/_nodes/stats #查看节点统计信息\n/_nodes/{nodeID}/hot_threads #查看该节点的热线程\n```\n\n### 其余tips\n\n\n#### scroll查询\n由于scroll会生成快照,因此段合并时不会立即删除小段,这意味着消耗更多的文件句柄.因此在查询过程中可以明确对哪些不用的scroll_id及时删除\n\n#### 查询时的路由\n\n我们知道,查询时路由有两种,一种是查询语句中包含routing信息,可以直接从指定分片中进行查询;\n\n还有一种则是分为Scatter分发,Gather收集两个过程,协调节点把请求分发到各个分片上执行,并收集返回结果.\n\n对于普通语句,可以尝试将频率大的字段进行routing设计,其中routing算法需要保证均匀分片\n\n对于普通语句的路由策略我们可以通过SearchType控制:\n* QUERY_THEN_FETCH:指的是第一次查询返回结果只返回docId和score,由协调节点排序后再依次去各个分片处获取.好处是节省带宽\n* QUERY_AND_FETCH: 指的第一次即返回docId,score和全量字段,由协调节点排序后直接返回客户端,节省io时间,但是许多无用消耗了带宽.\n* DFS_QUERY_THEN_FETCH:在QUERY_THEN_FETCH的基础上多了一个全局的词频计算,而不仅是分片的词频.打分更精确,但是性能更差一些\n* DFS_QUERY_AND_FETCH:与上类似.\n\n---\n\n* 角色隔离:由于默认配置中master节点也干了data的活,可能有时候影响整个集群的性能.因此通过角色隔离,将master和data角色区分开.使用配置较低的虚拟机为master\n* 避免脑裂:上述所属由于网络原因可能回导致集群中出现2个以上deaster,导致数据丢失,为防止这种情况,我们需要配置参数discovery.zen.minimum_master_nodes = (master_eligible_nodes/2)+1\n> discovery.zen.minimum_master_nodes表示选举主节点时参与选举的候选节点数(默认是1).\n> master_eligible_nodes表示master集群的主节点数.\n\n\n* 还有一个tips: 在使用es时出于es对内存和缓存需要性能的考虑,作者是建议关掉swap虚拟内存空间的.\n\n> 书中有一个很有点在这里提一下:\n堆内存最好不要超过32GB(为什么),因为在目前普遍的64位操作系统中,内存寻址范围变大,从而使得内存指针本身也变大了,有更大的内存空间会浪费在指针本身上,同时指针在主存和缓存间移动时也会占更大的贷款.\n>**Java在这里使用了内存压缩技术(Compressed Oops),他使得内存指针表示的是内存的偏移量而不是精确位置了,以每8个字节保存为一个引用,这样就可以以32位的寻址空间查询32GB的内存空间了,但是**一旦对内存超出32G时,指针就会切换回大指针从而浪费内存**.\n\n> 事实上 当内存达到40-50GB的时候才相当于压缩技术时的32GB\n","tags":["读书笔记","可伸缩服务架构+中间件"]},{"title":"缓存的本质和缓存使用的优秀实践","url":"/2020/03/20/缓存的本质和缓存使用的优秀实践/","content":"\n## 缓存特性Tips小记\n\n> 因为书中关于缓存的知识原理性的东西比较多，因此这里仅列出一些自己认为比较重要的点当作tips记录\n\n---\n## 一.CPU的缓存架构\n\n\n<img src=\"/imgs/cache_1.png\" width=\"50%\" />\n\n> 图一：CPU缓存架构 。\n> L1、L2为核级别的缓存，L3为多个核共享的缓存。\n\n* **cacheline 缓存单元**：缓存操作的最小单元，通过内存单元的物理地址来访问缓存。缓存在使用时是通过类似二位数组的形式来存取，我们常看到的**8WAY、16WAY**这种单位是用来描述缓存，通常用WAY表示列，SET表示行，通过防卫物理地址的高位和中位来选中一个缓存单元。\n> 通常的缓存单元大小为64个字节。\n* 伪共享：指的其实是多个线程如果读写一个cacheline里面的不同变量，会出现资源竞争而导致性能下降；或者是单线程每次的读写请求都没有命中cacheline；\n\n---\n## 二.分布式的缓存架构\n与CPU缓存架构相似，我们基本可以得出一个与其相似的分布式缓存架构出来。因此我们会面对于CPU缓存架构相同的问题**缓存高可用、缓存高并发**。\n\n### 2.1 缓存高可用\n目前主流的模式是**基于分片的异步复制的主从模型**。将数据按哈希环进行分片，然后针对不同分片还存在主从副本，同时异步进行主从同步。\n\n如果需要对缓存的高可用也可以通过强一致性协议来完成，即：\n1. 主开启写事务\n2. 主分发给子开启写事务\n3. 子写完返回成功给主\n4. 主收到所有子完成返回成功\n\n> redis的高可用是通过在每一个虚拟机节点上配置一个哨兵Sentinel，通过哨兵监控进行心跳检测、更新及选举。\n\n### 2.2 缓存高并发\n缓存理论上不存在高并发问题，问题一般都是出在IO成本上。\n\n### 2.3 Redis和Memcache两个解决方案的对比\n\n* **线程模型**\n    * redis是**单线程的非阻塞IO模型**，适合快速的短逻辑操作。**针对大量长逻辑的场景时应当考虑配置多个实例来提高CPU利用率**，官方推荐的是1台机器8个实例。此外为了提高单线程的IO效率，还**提供了管道来合并请求和执行批量操作**。依赖libevent库的两个epoll文件和自己实现了简单的事件通知模型\n    * memcache是多线程的非阻塞IO模型，直接依赖了libevent库。\n* **持久机制**\n    * redis支持RDB和AOF，基于定时的持久和基于操作的持久化。memcache依赖第三方组件\n* **客户端**\n    * redis的常见**客户端jedis使用的是阻塞I/O**，但可以配置线程池且支持一致性哈希分片。\n> 非阻塞I/O模型会有一个额外的请求线程（BOSS线程池），用来监听端口和处理就绪数据。工作者线程则用来计算。\n* **高可用**\n    * Redis支持节点复制，支持故障恢复和集群方案；memcache依赖第三方组件。\n* **事务**\n    * redis支持了一些线程安全和事务的命令，同时因为redis是单线程的，所以所有在服务器执行的操作都是原子性的。**但是跨客户端的操作并不能保证原子性**。\n* **内存分配**\n    * Redis 屏蔽了不同平台之间的差异，对内存分配函数封装了一层，程序中统一使用\"zmalloc\"、\"zfree\"系列函数，位于zmalloc.h/zmalloc.c文件中：\n        *  若系统中存在google的TC_MALLOC库，则使用tc_malloc系列函数代替原本的malloc函数\n        *  如果是Mac系统，则使用系统的内存分配函数。\n        *  其他情况对于每个分配好的空间前加一个定长字段来记录分配空间大小\n\n\n### 2.4 应用层的缓存应用模式\n\n#### 双读双写\n\n比较好理解，读即先读缓存，未命中则再读库后写缓存；写即先写库再写缓存。\n\n#### 异步更新\n\n这种模式是基于缓存的核心架构，**所有数据全量不过其写缓存**，并通过定时异步读取数据库中的变更数据更新到缓存中。\n> 定时异步或者是每次更新时异步读mysql的binlog来实现缓存的更新（或者是其他存储引擎，比如es；扩展一些，可以基于dataBus数据总线的概念，将所有db库的更新通过binlog推送至其他存储引擎中）\n\n#### 串联代理\n\n通过在应用和数据库中添加一层缓存代理组件，所有的读写操作通过代理组件做数据库的更新及维护，如Varnish缓存加速。\n\n\n### 2.5 缓存分片的三种方式\n\n这个非常类似之前的数据库分片方式\n\n* 客户端分片，通过扩展jar包实现分片解决方案\n* 代理分片，常见的有Codis框架\n* 集群分片，Redis3.0，同时集群可以实现高可用性。\n\n### 2.6缓存迁移\n\n分别为平滑迁移，停机迁移以及一致性hash环。其中平滑迁移方案同前一张的db方案\n\n### 2.7 缓存穿透、缓存并发和缓存雪崩\n\n上述三个点是缓存应用场景中常见的\n\n#### 缓存穿透\n\n穿透的含义就是由于大量请求未命中缓存导致请求直接访问到数据库中。\n\n预防措施：可以通过校验请求参数key的合法性，来过滤掉一部分的恶意供给\n\n#### 缓存并发\n\n缓存并发就是大量对同一key值请求的同时,key值缓存失效，造成大量的并发读库写缓存的操作。\n\n预防措施：**软过期**。保存一个缓存失效时间，可以派遣一个单独的线程从业务层面上去判断缓存是否过期，如果快过期则提前更新缓存。\n\n#### 缓存雪崩\n\n原因一般都是缓存服务器重启，或者缓存在同一时间内失效。会造成这一时间段内数据库压力大量上升。\n\n预防措施：通过对不同的缓存设置不同的失效时间，将失效时间分散。\n\n### 2.8 缓存对事务的支持\n\n我们知道Redis缓存可以在服务端通过单线程执行lua脚本，或事务命令来保证事务实现：\n\n```\n//通过LUA脚本实现数值递减至0的事务\npublic long decrByUntil0Lua(String key, long value){\n    if(value <=0 ){\n        return -1;\n    }\n\n    String script = \"local leftvalue = redis.call('get',KEYS[1]); \"\n    + \"if ARGV[1] - leftvalue > 0 then return nil ; else \"\n    + \"return redis.call(\"decrby\",KEY[1],ARGV[1]); end; \";\n\n    long leftValue = (Long) jedis.eval(script, 1,key,\"\"+value);\n\n    if(leftvalue == null){\n        return -1;\n    }\n    return leftValue;\n}\n```\n\n或者\n\n```\n//通过redis的事务命令来实现事务cas\npublic long decrByUntil0Cas(String key, long value){\n    if(value <=0 ){\n        return -1;\n    }\n    jedis.watch(key);\n\n    Transaction tx = jedis.multi();\n\n    String curr = tx.get(key).get();\n\n    if(Long.valueOf(curr) - value < 0){\n        //回滚\n        tx.discard();\n        return -1;\n    }\n\n    tx.dectBy(key,value);\n    //执行\n    List<Object> result = tx.exec();\n\n    if(result == null || result.isEmpty()){\n        return -1;\n    }\n\n    for(Object rt : result){\n        return Long.valueOf(rt.toString());\n    }\n\n    return -1;\n\n}\n```\n\n## 三.分布式缓存的设计及按理\n\n### 3.1 缓存设计的核心要素\n\n1. **容量规划**\n    * 缓存内容大小、数量\n    * 缓存淘汰策略\n    * 缓存数据结构\n    * 每秒读写峰值\n2. **性能优化**\n    * 客户端线程模型\n    * 缓存预热\n    * 分片\n    * 冷热数据比例\n3. **高可用**\n    * 复制模型\n    * 失效转移\n    * 持久策略\n    * 缓存重建\n4. **缓存监控**\n    * 缓存服务监控\n    * 容量监控\n    * 请求监控\n    * 响应时间监控\n5. **其他注意事项**\n    * 缓存穿透可能\n    * 大对象？\n    * 是否有需要实现分布式锁的场景\n    * 是否使用了缓存支持的lua脚本\n    * 是否避免了race condition(死锁)\n\n### 3.2 一些优秀的redis案例tips\n\n* 一定要加缓存监控，方便后续慢查询、大对象、内存使用请款问题的排查。\n* 任何缓存一定要设置失效时间，同时失效时间必须不能在同一时间内。\n* 访问缓存的连接一定要设置超时时间，避免负载上升后连接池超大从而雪崩的情况。\n* 低频的访问不要用缓存。\n* 缓存数据不能太大。\n* 对于value值较多的key，不推荐使用hgetall方法，会影响其他请求的访问。\n* 写缓存一定要写正确的数据，避免任何空指针，程序异常等。\n* 使用缓存的时候一定要有降级备案，尤其对核心业务。\n","tags":["读书笔记","可伸缩服务架构+中间件"]},{"title":"消息队列客户端的设计与实现","url":"/2020/03/20/消息队列客户端的设计与实现/","content":"\n## 设计目标\n设计一个MQ需要考虑的目标有:\n* 简单易用\n* 高性能\n* 高稳定\n\n### 简单易用\n作为kafka消息队列的客户端封装，需要屏蔽掉复杂的kafka初始化和调用步骤，为下游用户提供简单易用的配置和接口API。\n\n### 高性能\n消息队列客户端不能成为一次请求调用链中的瓶颈所在，因此需要设计一定的线程模型来支持高并发场景下的消息队列发送和接收。\n\n### 高稳定\n当系统关机时不能因为客户端框架而导致消息丢失等问题，需要日志记录，并且做到优雅关机。\n\n\n\n\n## 架构难点\n实现MQ客户端的设计，需要从应用场景上，结合性能分析需要做的设计有哪些：\n\n* 线程模型\n* 异常处理\n* 优雅关机\n\n### 线程模型\n作为简单易用的kafka客户端调用框架，满足各个场景需要的线程模式是必须的。文章提供了两种不同的模型：\n* 同步线程模型\n* 异步线程模型\n  * 消费者共享线程池\n  * 流独立线程池\n\n<img src=\"/imgs/kafka_1.png\" width=\"100%\" />\n\n\n\n\n\n### 优雅关机\n\n实现优雅关机需要做到：\n* 在JVM要退出时HOOK执行消息处理操作\n* 需要在JVM退出时HOOK等待后台线程池处理完当前消息（或设置等待时间），以防止后台线程在JVM退出后被马上kill掉，\n* 唤醒阻塞的Worker线程，通过中断线程池使退出。\n\n```\n//通过添加一个hook事件，能够在虚拟机关闭的时候调用方法\nprotected void initGracefullyShutdown(){\n    Runtime.getRuntime().addShutdownHook(new Thread(){\n        public void run(){\n            shutdownGracefully();\n        }\n    }\n}\n```\n\n### 消息处理客户端的实现解析\n\n最后贴一张书中有关消息处理客户端的解析图\n\n<img src=\"/imgs/kafka_2.png\" width=\"100%\" />\n","tags":["读书笔记","可伸缩服务架构+中间件"]},{"title":"轻量级的数据库分库分表架构与框架","url":"/2020/03/20/轻量级的数据库分库分表架构与框架/","content":"\n## 数据拆分类型及特性\n\n* 垂直拆分：业务层面上的拆分，将表（库）按字段（表）拆分成多个业务领域的表（库）。\n\n> 垂直拆分多为业务领域拆分，或者冷热分离；水平拆分多为数据量分割。\n\n> 冷热分离，读多写少的为冷数据，写多读少的为热数据。对于冷数据，可以使用更多的从库来分表；对于热数据，可以使用更多的主库来分库，或者考虑用缓存做异步写入。\n\n* 水平拆分：基于分片规则对大数据量的单表（库）查分成多个表（库）\n\n> 分库和分表所解决的问题：分表解决的是**单表查询带来的查询性能压力**；分库解决的是**单个数据库实例带来的网络I/O、内存、CPU、磁盘的性能压力**。\n\n> 水平拆分的特点是，提高系统的稳定和负载；缺点是数据是分散，无法利用数据库的Join操作，跨库Join性能较差；分片事务难以解决；还有合并分页的问题。\n\n## 分片方案\n\n* 客户端分片：\n 客户端分片即调用方调用时进行分片，**特点是侵入业务，性能较高，适合快速上线，容易追溯问题**，如**sharing JDBC**，实现方案分为：\n    *  应用层分片，将分配规则封装到函数中，在调用前执行。\n    *  定制JDBC分片，可以通过重写JDBC的接口，将分配规则嵌入。**特点是不侵入业务代码**。\n    *  定制ORM分片，使用ORM框架的扩展能力或者定制SQL来实现分片。\n* 代理分片：在应用和数据库之前加一层代理，由代理负责实现分片路由，特点是**不侵入业务代码，多一层节点对应性能有影响**。常见如Cobar,Mycat\n* 直接使用支持事务的分布式数据库,如OceanBase、TiDB，这些数据库内部已经实现分布式数据库下的事务支持，分片等，并对外透明。\n\n## 切片过程\n\n### 水平切片的切片方式\n\n* 按照hash切片，**适用于数据没有时效性的情况**。\n* 按照时间切片，**适用于有明显时间特性的数据**，对不同的访问频率的切片进行不同的硬件资源配置。\n\n两种方式都常用，有时也会结合使用。\n\n## 分布式事务处理\n\n> 严格遵守ACID的分布式事务我们称为刚性事务，而遵循BASE理论（基本可用：在故障出现时保证核心功能可用，软状态：允许中间状态出现，最终一致性：不要求分布式事务打成中时间点数据都是一致性的，但是保证达到某个时间点后，数据就处于了一致性了）的事务我们称为柔性事务。\n\n主流的分布式事务解决方案有很多：**两阶段提交协议(2PC)、最大努力保证模式**和**事务补偿机制**。\n\n### 两阶段提交协议(2PC)\n基于两阶段提交协议，事务管理器能够最大限度地保证跨数据库操作的事务的原子性，是分布式系统下**最严格的事务实现方法**。\n\n两阶段：**准备阶段**，**提交阶段**\n\n如图所示：\n\n<img src=\"/imgs/db_mid_2.png\" width=\"50%\" />\n\n\n> 这里的redo log 和 undo log 说明一下：\n> redo log 不是 binlog，他是基于innodb层产生的，并且记录的是物理格式层面的日志，记录的是数据库页的数据状态（比如对一个表新增数据后删除，那么对于redo log来说前后状态没有变化）。相比之下binlog更像是增量记载，每次读写的逻辑操作都会记录其中。\n\n缺点是：事务管理器需要和每个参与者进行准备和提交协调，当参与者过多的时候，会导致响应速度较慢，同时还容易出现死锁或不确定结果；同时由于2PC协议是阻塞协议，在极端形况下不能快速响应请求方，因此很少使用该协议作为解决方案。\n> 为了解决阻塞问题，而出现了3PC协议，但3PC仍需要事务管理器在参与者之间做协调。\n\n### 三阶段提交协议(3PC)\n\n待添加\n\n### 最大努力保证模式\n\n最大努力保证的核心思路是：在更新多个资源的时候，把多个资源的提交尽量延后到最后一刻处理。\n\n这种模式对一致性要求并不严格，适用于性能要求较高的场景。\n\n\n<img src=\"/imgs/db_mid_1.png\" height=\"50%\" />\n\n### 事务补偿机制\n\n事务补偿机制是，对于跨库事务场景下，可以通过补偿和重试使其在一定时间窗口内完成操作，从而保证事务的最终一致性。\n\n> 这种模式下需要记录更新时出现的问题、步骤、状态、环境，然后通过重试机制达到最终一致性。\n\n### TCC模式\n\n待添加\n\n## 事务路由\n\n### 可编程事务路由\n\n分布式场景下的事务路由是为了在应用层通过分片事务管理器路由到对应的数据源来处理事务。\n具体流程如下：\n\n\n\n<img src=\"/imgs/db_mid_3.png\" height=\"50%\" />\n\n分片事务管理器路由结构：\n\n\n<img src=\"/imgs/db_mid_5.png\" width=\"100%\" />\n\n> 通过上述demo可以使开发人员显式控制数据源的路由。\n\n### 声明式事务路由\n\n通常实际情况来说，我们都是通过注解的方式来开启事务，因此，通过在注解中表明使用那个数据库分片的事务管理器信息，可以使业务代码与事务代码进行分离解耦。\n\n\n<img src=\"/imgs/db_mid_4.png\" width=\"50%\" />\n\n> 声明式事务与上类似，区别是注解可配置路径实现分片。\n\n## 读写分离\n\n* 主库是集群的瓶颈，当写操作过多时会影响主库的稳定性，从而导致整个集群不能正常工作\n* 写操作首先写到主库上，其次从主库同步到从库上，因此当从库数量特别多的时候，或者读操作十分频繁的时候，会导致同步延迟增加。\n\n### 最佳实践\n\n* 当读操作压力很大时，可以考虑添加从库机器来分解大量读操作。\n* 当写操作压力大的时候，则必须进行分库。\n* 数据库硬件配置不一致而有性能不一致，因此可以通过各个数据库路由权重来实现负载均衡。\n\n### 分库分表产生的问题\n\n首先看看什么是分库分表和读写分离：\n\n\n<img src=\"/imgs/db_mid_6.png\" width=\"100%\" />\n\n#### 扩容和迁移\n\n\n<img src=\"/imgs/db_mid_7.png\" width=\"50%\" />\n\n\n扩容迁移时需要注意下几个问题：\n1. 按照新旧分片规则，对新旧数据库进行双写——————双写\n2. 将双写前的旧规则写入的数据，按照新规则写入新的数据库中——————迁移数据\n3. 将按照旧的分片规则的查询，改为新的分片规则查询——————切读\n4. 将双写的逻辑下线，保留写新库的逻辑————————下双写\n5. 删除旧分片写入规则的历史数据————————删除旧数据\n\n> 举例子说，假如数据是根据主键id值哈希5的余数，后续要扩容到7。则：\n* 先前主键余数大于4的主键id，则在写入旧库的同时写入新库。* 然后将先前大于4的主键id，按照新的余数7进行迁移。\n* 修改先前的大于4的查询逻辑为7的查询逻辑\n* 下线按照余数5的写入逻辑，只保留余数7的逻辑\n* 删除按照余数5的逻辑插入的数。\n\n在执行步骤2迁移旧数据的时候，因为数据量很大，会导致迁移过程中出现数据的更新，导致数据不一致。因此迁移过程中需要通过比对对一致的数据进行清洗，然后在做迭代迁移。\n\n在进行**金融交易类型**的数据时，最好进行**动静数据分离**，通过拉长双写的时间，再迁移那些某个时间点之后不会更新的静态数据，就能避免因为迁移而带来的数据不一致。\n\n在数据量巨大时，迁移若无法进行全量对比，就需要进行抽样对比。\n\n在迁移过程中可以通过记录更新日志，来提供多一种参考，实现最终的数据一致。\n\n> 解决分布式数据库的扩容问题的另一个有效的方法是，通过**一致性hash**进行分片。\n\n#### 查询问题\n\n分表场景下如果根据非分片字段进行查询，则会出现一些问题，常见的解决方法如下：\n* 查询多个分片后合并结果集，效率不高。\n* 根据查询场景进行多份分表冗余。\n* 使用搜索引擎。\n\n> 对于高并发的服务平台交易系统由于其核心系统SLA的级别较高（4个9或5个9）应该专门用于做交易，因此**交易系统的通常于查询系统分离，通过数据冗余给查询系统进行查询**。\n\n另一个问题，分表场景下基本不可能出现关联表的查询，因此必须借助**大数据平台**进行聚合查询。\n\n#### 分布式事务\n\n解决方案见上述\n\n#### 同组数据跨库\n\n尽量把一组数据放到一个数据库当中，即以单个数据库为最小单元。避免数据库中的数据依赖另一个数据库中的数据。\n","tags":["读书笔记","可伸缩服务架构+中间件"]},{"title":"分布式IDGenerator","url":"/2020/03/20/分布式IDGenerator/","content":"## 为什么不\n* 为什么不用UUID\n    * 存储占用完全的时间数据，存储性能差\n* 为什么不用数据自增ID\n    * ID依赖数据库会在数据库迁移、扩容、数据清洗、分库分表的时候遇到很多麻烦。\n* 为什么不用snowFlake\n    * 原因需要进一步探索 **todo**\n> 互联网相比银行，数据存在伸缩扩容的情况很频繁，因此自增ID不可取\n\n## 我们的需求\n* 全局唯一\n* 粗略有序：一般要么秒级有序，要么毫秒级有序。\n* 可反解\n* 可制造：即可复现旧ID\n* 高性能\n* 高可用\n* 可伸缩\n\n---\n\n> 那么设计一个IDGenerator的时候都需要考虑哪些因素呢？\n\n## 设计核心要点\n\n### 发布模式\n\n指用户使用的方式，比如**提供本地客户端（jar包）调用本地实现**、**提供本地客户端调用外部服务**或者**RESTful调用外部服务**。\n\n> 根据业务需要，发布模式也可以体现在ID中体现。\n> 思考，这三种发布模式的利弊各在哪里？\n> * 本地客户端调用本地实现：需要自行配置机器节点ID，优点是ID发布去中心化，不存在宕机风险，本地生成ID无需网络IO，快；缺点是ID难以统一维护\n> * 本地客户端调用远程服务：优点是ID服务便于统一维护升级，缺点是远程调用需解决网络IO延迟问题。\n> * RESTFul调用：除去上述优点之外还有一个支持跨平台应用调用，缺点同上。\n\n### 数据结构\n\n在ID的设计结构里，我们通常都需要考虑\n* 版本或扩展位，用于id生成器的版本迭代或用于扩展。\n* ID类型，用于表示秒级有序或者是毫秒级有序或者其他类型。\n* ID生成方式，这里用于发布模式的表示。\n* 时间，**核心结构**，秒级时间或毫秒级时间。\n* 序列号，**核心结构**，与时间一起保证ID有序\n* 机器ID，一个节点为一个ID，标识发布ID的机器节点。\n\n秒级有序结构\n\n字段|版本|类型|生成方式|秒级时间|序列号|机器ID\n---|---|---|---|---|---|---\n位数|63|62|60-61|30-59|10-29|0-9\n\n毫秒级有序结构\n\n字段|版本|类型|生成方式|秒级时间|序列号|机器ID\n---|---|---|---|---|---|---\n位数|63|62|60-61|20-59|10-19|0-9\n\n> 这里我们可以对比下秒级有序和毫秒级有序的区别：\n> * 首先秒级有序的时间跨度为（年）\n\n> $${\\frac{2^{30}}{365 \\times 60 \\times 60}} = 34$$\n\n> 而毫秒级的时间跨度为\n\n> $${\\frac{2^{40}}{1000 \\times 60 \\times 60 \\times 365}} = 34$$\n\n> 可容纳的时间跨度一致。\n> * 再结合序列来考虑即单机并发下每秒的ID生成数。在毫秒级场景下，单位毫秒内可最多产生2^10=1024个ID 。而秒级场景下，单位秒内可最多产生2^20=1048576个ID。**相对来说秒级场景下对峰值下的ID承受能力更强**\n>\n\n\n### 并发\n\n在ID生成过程中需要解决时间+序列的竞争问题\n* 通过concurrent包的ReentrantLock锁实现\n* 通过synchronized实现\n* 通过Atomic原子变量实现\n\n### 机器ID的分配方式\n\n机器ID需要统一管理，以保证ID序列不冲突，分配模式有\n\n* 通过在发号服务器上注册IP信息\n* 客户端自行配置\n\n> 通常通过ZK在进行机器ID生成\n\n### 时间同步\n\n时间同步需要注意的问题有：\n* 单机调整时间如何避免对ID生成产生影响\n* 每4年原子时钟和电子时钟会有1秒误差，即电子时钟每4年会慢原子时钟一秒如何解决\n\n#### 要点\n\n* 首先服务器集群均需要通过时间服务器同步时间，通过crontab 定时执行：\n\n> ntpdate -u 时间服务器\n\n* 若时间调整快于当前时间，则对ID生成无影响。\n* 其次为避免单机场景下因为时间调整后早于当前时间导致ID重复生成ID现象，：**生成ID时需记录原ID并进行比较，出现回退情况则拒绝生成ID**。\n* 对于发号服务器重启过程中出现时间调整早于当前时间且无原ID记录。则需**保证重启后的时间要晚于原当前时间**（可以通过延迟启动服务等）\n* 对于闰秒问题定时同步时间服务器即可。\n\n\n## 设计部分\n\n> Taik Is Cheap, Show Me Code\n\n[见练习代码](https://chouney.github.com/study)\n\n设计一个场景下的IDGenerator不仅仅需要满足ID生成需求，同样也需要支持ID反编译、ID回溯。\n","tags":["读书笔记","可伸缩服务架构+中间件"]},{"title":"《敏捷革命》阅读笔记","url":"/2019/07/09/《敏捷革命》阅读笔记/","content":"\n# 《敏捷革命》阅读笔记\n\n> 这本书里不时会冒出一些\"金句\"来，因此我把一些有感触的段落贴在这里。\n## 笔记tips\n\n> 我简单列一些阅读中有感悟的点记录下来。\n\n### 不要排斥计划变更\n每一个项目在开发过程中都需要人们去发现新问题，去激发自己的灵感。\n> 即使方案制定的尽可能完美，在执行过程仍然会出现新的问题，未来你永远无法预知。因此不要对执行方案中的计划变更排斥，要理解。\n\n### 敏捷团队结构\n一个敏捷团队应该是多功能、有自主权、得到授权的，有明确目标的。高自由度的团队执行能力和效率会很高。\n> 一个独立的团队目的是消除闸门障碍（闸门左侧的任务完成以后再能流转到闸门右侧）\n\n### 不要盲目为延期项目添加新成员\n布鲁克斯定律，为一个延误的IT项目添加人员，将导致更严重的延误。\n> 原因有两个，一个是增加人员后，新成员需要学习成本；另外就是*在团队中，每增加一个成员，沟通渠道就会大幅增加，沟通效果就会有折扣*。\n\n### 一次只做一件事\n一次只做一件事，我们可能曾经相信自己可以一心几用，然而事实就是，每当我从一件事转移到另一件事的过程，往往需要重新梳理这件事的上下文环境。这样的成本往往比你一件事一件事的做起来要慢得多。所以**一次把一件事情做好**\n\n## 为目标设立优先顺序\n一个产品的80%价值来自20%的功能，因此在开发进程中，我们应该优先解决那些能给项目带来最大价值的事项。\n\n\n## 读后感\n\n### 我对Scurm的理解\nScrum的核心在于动态，透明，计划随变化调整，吾日三省吾身，Run as One。\n\nScrum的关键词有：看板、冲刺周期、每日站会、产品负责人、Scrum主管。每个元素都需要发挥自己的职能：\n* 看板，降低团队沟通成本。\n* 冲刺周期，将实现目标分解到*能体现成果*的迭代单元。\n* 每日站会，降低团队沟通成本，暴露出项目目前问题。\n* 产品负责人，负责指定产品战略，确定事项优先顺序并且动态调整团队前进方向。职能与职位和级别无关。\n* Scrum主管，负责降低团队沟通成本，为成员解决问题排除障碍。*比如小明的负责的部分遇到一个问题需要部门B的合作，此时主管的职责就是向部门B申请资源来进行协同小明的工作*。\n> 作为scrum主管或者说作为一个teamleader的一个最重要角色就是问题解决者。通过例会（只是手段不是目的）来使成员间的信息透明化，把问题挤出来，并为你的成员们排除*解决问题的障碍*。Scrum主管的角色更像是清道夫，帮助成员清理前进道路上的障碍。\n> 产品负责人需要有自主决策权，他要对产品负责，同样他也要对产品最终的实现价值负责，同时产品负责人也需要有足够的时间与团队成员接触实时得到反馈，降低沟通成本，这也是为什么不建议高职务的管理人担任产品负责人。\n\n\n\n\n---\n\n> 敏捷软件开发宣言\n> * 人胜过流程\n> * 可以使用的软件胜过面面俱到的文件\n> * 客户合作胜过合同谈判\n> * 应对变化胜过遵循计划","tags":["读书笔记"]},{"title":"《技术的本质》———— 读后感","url":"/2018/12/11/技术的本质/","content":"\n> 陈述作者观点以及我的一些小小的感悟：\n\n### 一. 技术、现象、组合\n----\n1. **技术是通过技术之间的组合诞生的**。比如喷气机，就是由蒸汽动力和机械学科等技术组合进化而成。此外技术还有一个递归性，组成新技术的子技术也是其他技术组合而成的。（组合、继承）。\n\n2. 技术的建构不仅来自已有技术的组合，还来自于对自然世界现象的捕捉和使用（对现实世界本质的捕捉）。**即技术是对现象有目的的编程**。\n> 技术对现象进行捕捉和使用之后，形成一个装置会产生新的现象。而新的现象则会被新一轮的技术进行捕捉和使用。\n\n3. 作者对于技术的定义有几个关键词印象比较深刻：**装置、方法、流程、功能**。\n> 个人理解简直是为OOP量身定做的装置即对象，装置的功能即对象的功能。功能实现往往通过对象方法+控制器流程。\n> \n> 当然一个装置也可以拆分为多个子部件，其中可能有控制器元件和子装置元件。它们也有各自的对象方法或者控制器流程。\n\n4. 作者将技术进行功能性分组，即模块化，同时提倡**只有当模块被反复使用时才值得将技术进行分割做复用**。这一本质于亚当斯密的劳动分工理论类似：**生产数量足够大的情况下，才将工厂工作划分为专业工作**。\n> 这一理论告诉我们，不要过度设计，因为你永远不知道后面会有什么变故。\n\n5. 科学与技术的关系，就像新的设备和方法形成于被发现和使用的现象，同时设备反过来也会帮助建构进一步的知识和对本质的认知。\n\n6. 域的概念，类似于领域，指共性的技术或者可以共同工作的技术的集群。域对应语言，技术对应程序。\n> 设计程序必定需要一定的“语法”，而这个“语法”一定最终来源于自然规律或者是社会规律；如果你做的是基础设计，那么其理念一定源自现实的物理世界。如果你做的是业务设计，那么其理解也一定源自于现实的社会运行规则之中。\n\n7. 工程就是运用技术组合来解决问题。标准工程则是运用已知的技术组合来解决问题。其中设计则是关于解决方案的选择，**多优雅的设计都是基于标准工程之上。**\n> 所以为什么说源码重要，如果你不了解这一领域，你需要通过阅读同业的优秀源码来提升你的认知。如果你已经了解这一领域，你更需要基于优秀源码来思考改进和创新。\n\n\n### 二. 技术的变迁\n----\n\n8. 新技术的时间线起始于需求（目的）或者现象，并向对方那一端延伸，中间是一套标准工程，在延伸的过成功工程的每个环节都需要克服许多困难。\n\n9. 技术有两种发展机制：一个是内部替换，一个是结构深化。内部替换指的是**用更好的部件替换已经形成阻碍的某一部件**；结构深化是**寻找更好的部件或者是加入新的组件**。\n\n10. 自适应延伸：对旧有的成功原理的锁定所引起的现象称之为自适应延伸。人们在出现新的现象需求的时候往往会优先想到通过延伸旧的技术适用范围来解决。**当延伸到一定极致时，则会不可避免的遇到根本性阻碍**。从而使新的技术或者新的原理能够站出来\n> 可扩展性与重构：我们在原有系统上开发新需求时，会尽量考虑如何使原有系统适配新的需求。而到系统延伸至某一极限而难以维护，这时对系统的重构则不可避免。这符合我们日常开发准则。**YOU DONT NEED IT**，不要做过度设计，设计系统时尽量考虑眼前的需求即可。\n\n11. 域是如何进化的：在域的早期，都产生于一个已经存在的领域。会遇到发展上的一个阻碍，而当这个阻碍被突破之后可能会产生重大的影响，进而影响经济。这个时候的域已经脱离了母域。\n> 譬如人工智能领域在GPU矩阵运算成熟之前。以及未来的区块链\n\n12. 从新域的技术开始到新域全面发挥影响经济，通常需要几十年的事件。因为围绕这新域，人们通常需要时间来从域中采用有效技术来提升经济。有一个现有的经济结构进行冲过并适应新的域的过程。\n> 任何新兴的技术刚开始都是“生涩的”，人们在新兴技术里的探索出好的社会经济模式是需要持续的花费时间和精力的。所以没有热情和耐心是没有办法在新域中有所收获的。\n\n13. 技术之间的组合可以形成一个“网络“，技术对经济的影响潜力被叫做**\"机会利基\"**。两者之间的关系是互相影响的，当新技术诞生之后，他自然会对市场有一个机会利基。当他在市场竞争中成为胜者之后，那些失败的技术会递归性的失去活跃，让出他们的机会利基。而新技术则占据这些机会利基，为市场服务\n\n14. 作者通过实验一再强调：\"罗马不是一日建成的\"，**所有复杂的技术不是一气呵成的。**如果取掉所谓\"垫脚石的技术\"，实现复杂的新技术的难度可以说是成指数级上升（甚至比指数更高）。\n> 你如果想要一种问题的解决方案，OK，那么第一步一定是先去调研现状,站在巨人的肩膀上，而不是直接埋头扎进去。\n\n15. **经济与技术的关系**，作者将经济定义为”生产手段“，社会通过它来满足需求。而技术则构成了经济的框架。经济不可能脱离技术而独立存在，它是技术的一种表达形式。\n\n16. 它为新技术提供机会利基，新技术产生并胜出时会填补这些利基。技术集合+决策+活动+物流+服务流等=经济。同时技术创造经济，经济也会调节着新技术的创造。\n\n### 三.读后感\n----\n读完这本书感觉整体还是比较生涩难懂，勉强总结一下自己的一些读后感吧。\n\n1. 作者阐述了技术是通过技术之间的组合诞生，并以此不断的递归以保证技术的延续性。\n\n2. 技术是对现象有目的的编程。这表示我们的技术手段都是来源于现实——如果我来理解，就是不管你做的是业务架构还是技术架构，理解现实社会中对应的某些运行规则会对你大有帮助，就是所谓的领域吧。\n\n3. 一项创新的技术的诞生，是对原有技术研究之后通过组合来满足新的目的——我们在某一些技术上遇到瓶颈上时，同样也往往通过在原有模型之上做出的一些改进从而实现的，站在巨人的肩膀上不是一句偶然的话。\n\n4. 人们在出现新的现象需求的时候往往会优先想到通过延伸旧的技术适用范围来解决。当延伸到一定极致时，则会不可避免的遇到根本性阻碍。从而使新的技术或者新的原理能够站出来——我想到的只有重构原则，YOU DONT NEED IT。\n\n5. 从新域的技术开始到新域全面发挥影响经济，通常需要几十年的事件。因为围绕这新域，人们通常需要时间来从域中采用有效技术来提升经济。有一个现有的经济结构进行冲过并适应新的域的过程。任何新兴的技术刚开始都是“生涩的”，人们在新兴技术里的探索出好的社会经济模式是需要持续的花费时间和精力的。所以没有热情和耐心是没有办法在新域中有所收获的。","tags":["读书笔记"]},{"title":"函数式编程思维笔记","url":"/2018/11/11/函数式编程思维笔记/","content":"\n- 面向对象编程通过封装不确定因素来使代码能被人理解；函数式编程通过尽量减少不确定因素来使代码能被人理解。 \n\n- 函数式思维编程，意味着你需要摒弃低层次的具体细节，向更高抽象的层次进行靠拢。让埋头于细节的开发更着眼于抽象的类型归类。\n\n- 物理学中把机械能通常分为势能和动能，传统的思维力的操作相当于动能，而函数式编程中会通过一些列的前置处理，我们叫势能。然后再通过操作进行动能转换。函数式编程这里叫做缓求值(lazy evaluation)\n\n>个人理解，函数式编程的核心思想在于：无状态。**函数式编程即通过无状态的函数加以其他优化特性，将这些函数组件进行拼接的过程**。优势就是无状态的函数可以减少很多不确定的因素，提高程序可用性和可维护性。\n\n## 一.转变思维：\n集合的日常操作中基本上包含了以下几个用的基本结构单元：过滤（filter）、映射(mapping)、折叠(folder)/化约(reduce)\n\n-----------\n\n## 二.权责让渡：\n函数式编程的好处之一，将低层次的具体细节控制权交给运行时。函数式编程通过5中让渡控制权的方式来解脱你们繁琐重复的操作。\n\n### 2.1 迭代让位于高阶函数\n类似于java 8 StreamApi的实现思想，将具体的迭代操作交由函数控制，我们只负责具体的实现逻辑。\n\n### 2.2 闭包（Closure）\n这种函数暗地绑定了函数内相关的所有变量，即把他用到的所有东西都放在了一个上下文当中。如下所示（Groovy）:\n```\nclass Employee {\n    def name, salary \n} \n \ndef paidMore(amount) {\n    return {Employee e -> e.salary > amount} \n} \n \nisHighPaid = paidMore(100000)\n\n```\n闭包在这里体现的函数式思维是：**让运行时去管理状态**。\n\n> 传统命令式思维编程是通过维护状态来建立编程模型，而函数式编程思维是通过维护行为来建立模型。举个例子来说，对于一个变量自增的问题来说，命令式编程会把维护状态，每次调用均执行状态变更；而函数式思维来说，会通过闭包的方式将代码块和变量封闭在上下文之中，将状态维护下沉到运行时。\n\n```\ndef Closure makeCounter() {\n    def local_variable = 0   \n    return {\n        return local_variable += 1 \n    } \n} \nc1 = makeCounter()\nc1()                  \nc1() \nc1() \nc2 = makeCounter()   \nprintln \"C1 = ${c1()}, C2 = ${c2()}\" \n// output: C1 = 4, C2 = 1\n```\n### 2.3 柯里化和函数的部分施用（currying & partial application）\n\n柯里化指的是**将一个多个参数的函数转变为若干成一连串单参数函数的变换。**它描述的是变换的过程，不涉及变换之后对函数的调用。调用者可以决定对多少个参数实施变换，余下的部分将衍生为一个参数数目较少的新函数。例如:process(x,y,z)=>process(x)(y)(z)。其中process(x)和process(y)(z)x均为单个传参。\n\n部分施用指的是通过设置默认传参将多参调用的函数转为为少量参数调用的函数。\n\ncurrying举个例子(Groovy)：\n\n```\ndef product = { x, y -> x * y } \n \ndef quadrate = product.curry(4)\n\ndef octate = product.curry(8)\n \nprintln \"4x4: ${quadrate.call(4)}\"\n\nprintln \"8x5: ${octate(5)}\" \n```\n定义了product一个函数，通过function的curry方法固定了第一个参数，随后通过函数调用时传入的第二个参数来确定函数的返回值。\n\n另一个currying例子(Scala)\n\n\n> 在大多数函数式语言（Groovy、Scala）中，柯里化和函数部分施用往往都是类似的，如上所示,在Groovy中,调用function.curry(a,b)则是部分施用,而调用function.curry(a).curry(b)则是柯里化。他们的结果往往相同。\n\n```\ndef filter(list:List[Int], func:Int=>Boolean): List[Int] =\n    if(list.isEmpty) list\n    else if(func(list.head)) list.head :: filter(list.tail,func)\n    else filter(list.tail,func)\n\ndef func(n:Int)(x:Int) = ((x % n) == 0)\n\nvar l = List(1,2,3,4,5,6,7,8,9)\nprintln(filter(l,func(2)))\nprintln(filter(l,func(5)))\n```\n通过调用filter时固定func的第一个参数实现柯里化\n\n一个函数部分施用的例子(Scala叫模式匹配,match&case):\n```\ndef price(product:String) : Double = \n    product match {\n        case \"apple\" => 10\n        case \"banana\" => 20\n    }\n\ndef withTax(cost:Double, city:String) : Double =\n    city match {\n        case \"BJ\" => cost * 4\n        case \"HZ\" => cost * 2\n    }\n\nvar localTax = withTax(_:Double,\"BJ\")\nprintln(localTax(price(\"apple\")))\n```\n在该例子中，通过对withTax固定绑定了\"BJ\"参数，从而在后续的调用中省去了city参数的传入，实现partial。\n\n> currying和partial application的应用场景通常用于：函数工厂、模板方法设计模式、隐含参数。\n\n### 2.4 递归\n函数式思维中的迭代和传统命令行思维中的迭代有所不同，比如：\n> 对于列表3，5，11，6，22，44，32，我们通常的思维是基于索引0，1，2，3，4，5，6，7存储的。然而在函数式递归思维中，通常都表示为3和5，11，6，22，44，43，分成了当前的元素头以及剩余元素列表。\n\n通过list.head以及list.tail的切分思维，我们可以很容易的通过递归来实现逻辑（递归毕竟存在效率问题）\n\n> **这个递归的思想的关键之处在于权责让渡，每次递归都会将运行时的状态交给到函数自身当中，避免了外界进行状态干预。**\n\n> 另外值得注意的是，递归没有被经常使用是因为栈的空间占用，Scala等语言分别采用了不同的方式来规避这方面的局限。开发者也可以通过尾调用优化(tail-call optimization)写法，即**当递归调用是函数执行的最后一个调用的时候，运行时往往可以在栈里就地更新，而不需要增加新的栈空间**。很多函数式语言都实现了没有栈增长的尾递归。\n\n### 2.5 Stream和作业顺序重排\n在Stream API中，聪明的运行时会替我们重新安排缓求值操作的执行顺序，以取得最佳的运算效率。\n\n-----------\n\n## 三.用巧不用蛮\n函数式语言的优势在于可以通过其两个特性实现效率的提高，**记忆(memoization)和缓求值(laziness) **。\n记忆即通过缓存技术来提高一个常用函数的性能，一般来说**纯函数**比较适合缓存技术，指的其结果完全由输入参数决定而不引用其他值可变的类字段。\n> 缓存并非是万能的，也要付出一些代价，缓存的施用也就意味着出现了状态维护成本。\n\n一些函数式语言支持其记忆特性，以Groovy为例，以可通过memoize()方法记忆一个函数(**运用元函数：即操纵的是函数本身而非结果**)\n\njava8之前的语言本身并不支持缓求值，但是可以通过迭代器iterator.next()来实现函数的缓求值。\n\nGroovy如何利用缓求值构造缓求值列表：通过**闭包参数化**，例如：\n```\ndef prepend(val, closure) { new LazyList(val, closure) }\ndef integers(n) { prepend(n, { integers(n + 1) }) }\n@Test\npublic void lazy_list_acts_like_a_list() {\n def naturalNumbers = integers(1)\n assertEquals('1 2 3 4 5 6 7 8 9 10', naturalNumbers.getHead(10).join(' '))\n def evenNumbers = naturalNumbers.filter { it % 2 == 0 }\n assertEquals('2 4 6 8 10 12 14 16 18 20', evenNumbers.getHead(10).join(' '))\n}\n```\n这里的LazyList构造方法的两个参数分别是List的head和tail，getHead的实现实际上是链表的迭代。通过列表初始化式将闭包进行传参实现tail指向为一个闭包函数，在使用时才被调用，以此实现缓求值列表。\n\n--------\n\n## 四.演化的语言\n函数式和面向对象语言对待代码重用的方式不一样，面向对象语言倾向于对各种功能的数据结构进行复用；函数式语言则鼓励在数据结构上使用各种共通变换。\n> 100个函数操作一种数据结构的组合，要好过10个函数操作10种数据结构的组合。 ———— Alan Perlis\n\n### 4.1 分发机制\n先前介绍过的Scala的模式匹配特性就是一种分发机制。这个词被用来泛称各种语言中用作**动态地选择行为**的特性。\n#### 4.1.1 Groovy中分发机制\n当Java中执行条件筛选时，绝大多数是不适用于switch语句只能施用if的，大量的if语句难以阅读。**通常大量的if的解决方案是通过工厂方法模式进行缓解**。但是Groovy通过更灵活的switch语句在语法上改进了不少：\n```\nclass LetterGrade {\n def gradeFromScore(score) {\n switch (score) {\n case 90..100 : return \"A\"\n case 80..<90 : return \"B\"\n case 70..<80 : return \"C\"\n case 60..<70 : return \"D\"\n case 0..<60 : return \"F\"\n case ~\"[ABCDFabcdf]\" : return score.toUpperCase()\n default: throw new IllegalArgumentException(\"Invalid score: ${score}\")\n }\n }\n}\n```\n#### 4.1.2 Scala\nScala的模式匹配基于case类，case类类名可以直接用作一个工厂方法，不用new就可以创造一个新实例。经传参的参数值均为不可变的。\n```\nclass Color(val red:Int, val green:Int, val blue:Int)\ncase class Red(r:Int) extends Color(r, 0, 0)\ncase class Green(g:Int) extends Color(0, g, 0)\ncase class Blue(b:Int) extends Color(0, 0, b)\n\ndef printColor(c:Color) = c match {\n case Red(v) => println(\"Red: \" + v)\n case Green(v) => println(\"Green: \" + v)\n case Blue(v) => println(\"Blue: \" + v)\n case col:Color => {\n print(\"R: \" + col.red + \", \")\n print(\"G: \" + col.green + \", \")\n println(\"B: \" + col.blue)\n }\n case null => println(\"invalid color\")\n}\n```\n可以看出groovy的在switch中的case中并不局限于某一个类型，而是更加灵活的可以是区间，正则表达式等等。\n### 4.2 运算符重载\nJava并没有运算特性，这是设计阶段就刻意做出的决定，认为运算符重载会给语言增加过多的复杂性。不过JVM平台的衍生语言均支持了运算符的重载特性。\n\n#### 4.2.1 Groovy\nGroovy通过将运算符映射成方法，对运算符的重载映射到了对方法的重写上。\n\n运算符 | 方法\n---|---\nx + y | x.plus(y)\nx * y| x.multiply(y)\nx / y | x.div(y)\nx ** y | x.power(y)\n\n#### 4.2.2 Scala\nScala的运算符重载中并不区分运算符和方法，例如：\n```\nfinal class Complex(val real: Int, val imaginary: Int) extends Ordered[Complex] {\n def +(operand: Complex) =\n    new Complex(real + operand.real, imaginary + operand.imaginary)\n \n def +(operand: Int) =\n    new Complex(real + operand, imaginary)\n \n def -(operand: Complex) =\n     new Complex(real - operand.real, imaginary - operand.imaginary)\n \n def -(operand: Int) =\n     new Complex(real - operand, imaginary)\n \n def *(operand: Complex) =\n    new Complex(real * operand.real - imaginary * operand.imaginary,\n        real * operand.imaginary + imaginary * operand.real)\n}\n```\n\n### 4.3 函数式的数据结构\n\n#### 4.3.1 函数式中的错误处理\n函数式语言没有Java中那样异常的概念，因为函数式语言更偏好没有副作用的纯函数，如果设计了抛异常行为反而是一种副作用。因此需要语言均在返回值里表明错误并作出相应。目前常用的方法：有**互斥二元集合表示是否成功以及正常结果**、**Option类返回None或者正常结果**；\n\n### 4.4 模式与重用\n\n#### 4.4.1 函数式语言中的设计模式\n传统设计模式在函数式语言中一部分已经不再适用了，模式最终大致都有三种归宿：模式被吸收成为语言的一部分、模式在函数范式下依然存在但是细节已经有了变化、模式在新的语言范式下获得了原本没有的能力。\n\n#### 4.4.2 函数的复用\n面向对象语言中的重用思想，是利用设计模式来模拟现实问题，找出对应的模式予以解决。函数式语言则更加注重于问题的数学范畴。例如列表，大多数应用都会对列表进行操作，而函数式的重用就可以建立在列表之。\n\n> 面向对象的重用更多的是通过继承来实现，会存在变量状态的耦合（父子属性共用）；而在某些场景中，使用函数思维的通过定义纯函数来进行重用效果会更加显著。这无关于使用的语言以及类，跟思维有关。\n\n----------\n## 五.现实应用\n\n### 5.1 Java 8\n这里只贴一些平时还不是很了解的知识\nPredicate<T>其实是个返回Boolean值的函数，让我们可以显式的创造：\n```\nPredicate<String> p = (name) -> name.startsWith(\"Mr\");\n```\n被赋值的p是作为条件的lambda块\n\n#### 5.1.1 函数式接口\n函数式接口其实是对SAM(Single Abstract Method)的优秀契合，SAM是Java的传统习惯用法，比如Runnable、Callable等。Java8通过对接口进行函数化配置@FuncationInterface，用户即可通过lambda对来实现接口。\n>接口的默认方法可以认为是对\"mixin\"特性的一种模仿，Comparator接口是默认方法非常耀眼的例子。\n\n#### 5.1.2 stream\nJava8的stream流式编码风格特性在很多方面都与集合相似，但是有一些区别。\n* 不存储值，只做管道输入输出\n* 函数式风格，避免与状态发生关联。\n* 缓求值\n* 可以无边界。\n* 消耗品，用过之后需要重新生成才能操作。\n> stream的操作分为中间操作和终结操作，中间操作返回stream并总是缓求值的。终结操作遍历stream产生结果值。\n\n### 5.2 函数式的基础设施\n\n本节重点将到如何利用函数式思想在更重要的应用架构内发挥作用\n\n#### 5.2.1 架构\n函数式的架构的核心思路在于贯彻**值不可变**的思路。虽然会有一些前期设计的复杂性，但是后续工作会十分简化。\n值不可变的特性在一些地方会发挥其特有的优势，比如：\n* 测试，如果严格限制了可变性，需要测试的地方就会随之减少。\n* 线程安全，如果值不可变，则完全不可能发生同步方面的问题。\n\n实现一个值不可变的Java类，需要做到一下事情：\n* 把所有的字段都标记为final\n* 吧类标记为final\n* 不提供无参数的构造器，因为需要通过构造器来设计一切状态。\n* 除了构造器外，避免提供制造变化的方法，**不但要避免setXX方法，还要地方任何返回值可变的对象引用，因为final不等于他指向的对象状态不变更。**\n\n> 为此，Groovy提供了语法糖衣来掩盖了繁琐的值不可变实现细节@Immutable\n\n传统的ORM架构是完全基于值可变对象之上的，因此现有系统需要重大改造。**比如CQRS(Command-Query Responsibility Segregation)命令-查询职责隔离架构**。\n\n传统应用架构把读数据和写数据交织在一起，比如关系型数据库，开发者把精力用在了对象-关系的映射上。在传统架构中，逻辑层以及模型层需要实现业务规则和校验，就必须同时兼顾读和写，这就增加了复杂性\n\nCQRS通过分离架构中负责读取的部分和负责命令的部分，部分简化了架构。读取的部分天生具有值不变性，可以通过纯函数或者闭包的方法实现。更新则需要专门去设计。读写分离意味着逻辑处理过程也是分离的，甚至执行单元也是分离的。CQRS的优势明显，缺点依然明显：在读写分离的情况下很难实现事务。通常都是通过最终一致性来保证数据的。\n\n#### 5.2.2 Web框架\n\n为什么说函数式语言与web框架是天作之合呢？**首先Web基于http协议，而http协议是无状态的，这意味着每一次从请求到响应的过程都可以看作一次函数的变换。**。大多数函数式的WebWeb应用都使用函数来处理Web请求，有一些甚至也提供了语法糖衣来简化这方面的操作。\n\n#### 5.2.3 数据库\n数据库上的函数式编程方式是令人眼前一亮的。Datomic是一种值不可变的数据库，与传统关系型数据库不同的是，首先Datomic存储的是值而非数据，每一个值都会只想一个具体的实例，如果有多条数据存在同一值则会指向同一原始实例，极大的提高了空间利用率。其次每一笔数据都会打上时间戳，每一笔新的纪录都不会覆盖旧纪录。Dotamic的设计产生了一些有意思的结果：\n* 悠久纪录所有schema变更和数据变更，由于保留了旧数据，因此数据库可以轻易的进行回滚。\n* 其架构天然的支持读写分离，不会存在因为查询而写入延迟的情况\n* 完美支持事件驱动型架构，Dotamic记录数据的特点决定了整个事件流都可以被回溯和重放。\n\n### 5.3 多语言与多范式\n多范式是指现代的编程语言大多支持多种比如面向对象、元编程、函数式、过程式等编程范式。\n面向对象、函数式、过程式都好理解，这里重点解释下元编程的概念。\n#### 5.3.1 元编程\n元编程指的是通过语言提供的扩展机制**对已有的类添加新的方法**。以Groovy为例：\n\n```\nInteger.metaClass.isPerfect = {->\n Classifier.isPerfect(delegate)\n}\nInteger.metaClass.isAbundant = {->\n Classifier.isAbundant(delegate)\n}\nInteger.metaClass.isDeficient = {->\n Classifier.isDeficient(delegate)\n}\n```\n上例通过扩展Integer的方法，为其添加了完美数的判断。这里的Classifier是已有实现类，不用过多引申。重点是为了表现通过Integer的metaClass实现对Integer类所有实例的方法扩展。\n\n#### 5.3.2 语言分类\n\n语言分类可以看作是一个二维平面坐标轴，垂直方向为动态、静态特性；水平方向为强、弱特性。**强类型语言是一定知道并持有自己的类型信息，允许反射**，**而弱类型语言就相对不了解变量所指向的内容**。比如C就是弱类型语言，因为他的变量本质上只是一组可以被任意解读的二进制集合。**动态类型指的是允许推迟指定类型**，**静态类型指的是事先指定变量和函数的类型**。C就是静态类型语言。","tags":["读书笔记"]},{"title":"阿里百万级mq优秀源码学习","url":"/2018/10/11/阿里百万级mq优秀源码学习/","content":"> 阿里复赛以及学习的源码地址在：https://code.aliyun.com/250577914/queuerace2018\n\n### 思路\n> 学习优秀的源码首先需要学习编码者的思路风格。\n\n1. **确定文件读写方式**：mq的构建必须用到文件磁盘，那么对于IO的策略Java提供了三个方法：标准IO、NIO、Mmap。针对这个作者基于对当前优秀mq的源码为入口进行调研及实验，并结合当前应用场景进行分析\n2. **确定存储结构和索引结构**：mq中必然存在消息主体数据以及确定消息数据位置的索引数据。比赛规则要求存在对100w队列进行随机消费以及顺序消费。那么作者针对消息的消费场景决定**同一队列的消息尽可能存储在一起**，并通过**写缓冲区来减小IO次数**、**按块存储的稀疏索引降低索引文件数量**。\n> 为了能更高效的进行IO，我们不可能逐条的存取消息。而如何确定读写缓冲区大小以及缓冲区优化作者也给了一些思路。**如块读写**\n\n","tags":["读书笔记","学习"]},{"title":"Stream Piplines结构及原理","url":"/2018/09/18/Stream Piplines结构及原理/","content":"\n> 内容学习自：https://github.com/CarpenterLee/JavaLambdaInternals\n\n## Stream Piplines结构及原理\n在学习Stream源码之前，我们需要先了解Stream的结构，Stream操作分类：\n<table width=\"90%\" border-spacing=\"0\" border=\"1\"><tr><td colspan=\"3\" align=\"center\"  border=\"0\">Stream操作分类</td></tr><tr><td rowspan=\"2\"  border=\"1\">中间操作(Intermediate operations)</td><td>无状态(Stateless)</td><td>unordered() filter() map() mapToInt() mapToLong() mapToDouble() flatMap() flatMapToInt() flatMapToLong() flatMapToDouble() peek()</td></tr><tr><td>有状态(Stateful)</td><td>distinct() sorted() sorted() limit() skip() </td></tr><tr><td rowspan=\"2\"  border=\"1\">结束操作(Terminal operations)</td><td>非短路操作</td><td>forEach() forEachOrdered() toArray() reduce() collect() max() min() count()</td></tr><tr><td>短路操作(short-circuiting)</td><td>anyMatch() allMatch() noneMatch() findFirst() findAny()</td></tr></table>\n\n* 中间操作即只进行标记而不进行计算，结束操作则反之对数据进行计算。\n* 中间操作的无状态表示操作之间无序，每次操作之间互不影响；有状态则是反之，每次的操作结果顺序之间可能存在影响，例如:sorted()、limit()。\n* 结束操作的非短路操作即计算期间不会因为某一个环节而终止计算；短路操作反之则是会因为某一环节而终止计算。\n\n------------\n\n### 结构设计\n实现一个Stream流需要解决一下问题：\n1. 如何记录操作？\n2. 操作如何叠加？\n3. 叠加后的操作如何执行？\n4. 执行后如何取结果\n\n#### 如何记录操作\n\n<img src=\"/imgs/stream_1.png\" width=\"50%\" align=\"right\" />\n\nStream把一个中间操作归类为了一个<数据源，操作，回调函数>的数据结构。Stream中把这样一个状态成为stage，并通过实例化的PipelineHelper来表现这个状态。上图即相关Stream的接口与继承类图示。\n\n<img src=\"/imgs/stream_2.png\" width=\"90%\"/>\n\n其中ReferencePipeline为BaseAbstract类实现了大多数操作的记录，表示引用类型的Stream。除此之外还有IntPipeline、LongPipeline以及DoublePipeline的基本类型的Stream。\n\n上图流水组织结构可以看出，操作流水的记录通过一个双向链表组成。其中Head为链表的头结点，其余结点根据操作的状态分别用不同的结点表示。\n\n#### 操作如何叠加\n这个问题看起来有点简单，叠加实现只要在每个当前的Stage调用回调函数后执行其下一个Stage结点的调用函数就行了。但是具体要如何实现呢？当前的stage又如何知道何时调用下一个stage结点的回调函数？\n我们还需要一个数据结构来管理stage之间的调用关系和资源。\nStream定义了Sink接口来完成对stage之间的调用关系和资源。\n\n<table width=\"90%\" border=\"1\"><tr><td align=\"center\">方法名</td><td align=\"center\">作用</td></tr><tr><td>void begin(long size)</td><td>开始遍历元素之前调用该方法，通知Sink做好准备。</td></tr><tr><td>void end()</td><td>所有元素遍历完成之后调用，通知Sink没有更多的元素了。</td></tr><tr><td>boolean cancellationRequested()</td><td>是否可以结束操作，可以让短路操作尽早结束。</td></tr><tr><td>void accept(T t)</td><td>遍历元素时调用，接受一个待处理元素，并对元素进行处理。Stage把自己包含的操作和回调方法封装到该方法里，前一个Stage只需要调用当前Stage.accept(T t)方法就行了。</td></tr></table>\n\n> 这里记住stage只是维护自身状态，并不关心下一个stage结点的操作是什么以及结点间的执行顺序，这些都是通过sink封装一个统一的accept、begin、end()操作来定义stage结点间的执行顺序的。\n\n> 实际上Stream API内部实现的的本质，就是如何重载Sink的这四个接口方法\n\n通过Sink的begin()、end()、accept()递归调用顺序来控制下游Stream的调用。\n\n#### 叠加之后的操作如何执行\n\n<img src=\"/imgs/stream_3.png?raw=true\" width=\"28%\" align=\"right\" />\n\nStream的流水线的调用关系如上所示，每级sink都有一个封装了stage三元组以及下一级sink的引用。每级中间操作的sink都包含两个操作，每级终极操作包含一个操作如上图。\n\n**上游的sink是如何调用sink的**，理所当然的想法是在每个Pipeline结点添加一个sink引用，引用到下一级。但是Stream并没有这样做，而是通过定义一个方法onWrapSink()来返回一个Sink。为什么通过方法做而不是用引用？**因为通过onWrapSink()方法可以将当前sink与下一级sink包装成一个新的sink**。再结合AbstractPipline.wrapSink()方法来看就明白了：\n\n```\n/** \n *  自底向上遍历sink，并以此包装。\n *  返回第一个stage的sink封装。\n **/\n \nfinal <P_IN> Sink<P_IN> wrapSink(Sink<E_OUT> sink) {\n    Objects.requireNonNull(sink);\n    for (AbstractPipeline p=AbstractPipeline.this; p.depth > 0; p=p.previousStage) {\n        sink = p.opWrapSink(p.previousStage.combinedFlags, sink);\n    }\n    return (Sink<P_IN>) sink;\n}\n```\n执行这个返回的sink就相当于执行了整个流水线了：\n\n```\n// AbstractPipeline.copyInto(),对spliterator代表的数据执行wrappedSink代表的操作。\nfinal <P_IN> void copyInto(Sink<P_IN> wrappedSink, Spliterator<P_IN> spliterator) {\n    ...\n    if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) {\n        // 通知开始遍历\n        wrappedSink.begin(spliterator.getExactSizeIfKnown());\n        // 迭代\n        spliterator.forEachRemaining(wrappedSink);\n        // 通知遍历结束\n        wrappedSink.end();\n    }\n    ...\n}\n```\n\n> 这里需要知道的是spliterator是容器的一种迭代器，可拆分迭代器，可以通过trySplit()方法尝试将容器拆分成两个来迭代，来分解负载以便多线程处理。\n\n#### 执行后的结果在哪里\n\n流水线的结果一般有如下几种：\n<table width=\"80%\" border=\"1\"><tr><td align=\"center\">返回类型</td><td align=\"center\">对应的结束操作</td></tr><tr><td>boolean</td><td>anyMatch() allMatch() noneMatch()</td></tr><tr><td>Optional</td><td>findFirst() findAny()</td></tr><tr><td>归约结果</td><td>reduce() collect()</td></tr><tr><td>数组</td><td>toArray()</td></tr></table>\n\n##### 源码解读\n\n\n> 是否有流的顺序优化？ 结构优化？ 有待读源码\n","tags":["读书笔记","源码阅读","java"]},{"title":"QPS与最佳线程数设计的学习","url":"/2018/04/11/QPS/","content":"\n## QPS与最佳线程数设计的学习\n\n### 一.QPS和RT\n\n在理解最佳线程数之前，需要了解两个概念\n\n**QPS**：每秒处理请求次数，指的是一次业务场景下请求。\n\n**RT**：响应时间，从请求发送后到请求返回后的响应时间\n> 通常来说分为客户端RT和服务端RT，其中因为客户端的请求要经过服务端，因此客户端RT往往要大于服务端RT\n\n> 一般上：RT = CPU Time + CPU Wait\n\n\n### 二.QPS和RT的关系\n\n**在考虑单个线程的环境下**:\n\n$$QPS =  {1s \\over RT}$$\n即：\n$$QPS={1s \\over (CPU Time + CPU Wait)}$$\n\n> 这个是什么意思呢。在单个线程的环境下。QPS相当于1s内处理请求的数量，那么当一个请求真正需要的时间其实为CPU的计算时间+CPU的等待时间（IO阻塞）。\n\n**那么在考虑多线程的环境下**:\n\n最简单的QPS计算就是多线程场景:\n$$QPS = {threadNum \\times SimpleThread QPS }$$\n> 就是单线程下的QPS乘以线程数就好了。(虽然事实并不是这样，因为有线程上下文切换以及一系列的问题)\n \n \n### 三.最佳线程数\n\nCPU等待的这段时间不可能被浪费掉，所以如果能做到把这部分时间转化为CPU Time，那么需要的线程数就可以通过计算得出：\n$$threadNum = {(CPU Wait + CPU Time)  \\over  CPU Time}$$\n即：单核CPU计算能力所支持的最佳线程数等于**一次请求下CPU的全周期与一次请求下CPU的计算时间的比值**\n\n> 公式中的线程数被用来弥补CPUWait时间，使CPU计算时间最大化。\n\n\n然而在现实场景下还需要考虑到CPU Core的数量以及CPU利用率的情况，CPU Core不用讲，CPU利用率指的是业务系统场景下对CPU的利用率。\n\n因为在多线程环境下，因为线程之间竞争计算资源导致业务系统对CPU资源的利用率下降。比如GC过程、锁竞争等。\n\n所以以此为基础再加上CPU Core的数量以及CPU的利用率，可以得出最终公式：\n$$threadNum = \\frac{(CPU Wait + CPU Time) }{CPU Time} \\times {CPU CoreNum \\times CPU Ratio}$$\n最终我们可以得出多线程下的最佳QPS：\n{% math %}\n\\begin{aligned}\nmutiThreadQPS & = {threadNum \\times simpleQPS} \\\\ \n & =  \\frac{(CPU Wait + CPU Time) }{CPU Time} \\times {CPU CoreNum \\times CPU Ratio} \\times  \\frac{1s}{(CPU Time + CPU Wait ))} \\\\\n & = \\frac{1s}{CPU Time} \\times {CPU CoreNum \\times CPU Ratio}\n \\end{aligned}\n{% endmath %}\n即：\n$$mutiThreadQPS = {1s \\over CPU Time} \\times {CPU CoreNum \\times CPU Ratio}$$\n\n\n### 四.计算能力与阿姆达尔定律\n\n最佳线程池情况下的QPS依赖于CPU Time、CPU CoreNum、以及CPU Ratio。\n\n根据公式可以很轻松看出来**减少CPU 计算时间**、**增加CPU核**或者**提高CPU利用率**都可以提高业务的QPS效率（感觉很废话...）。\n\n**那么问题来了**。\n\n是不是CPU核与系统QPS成线性比例呢？\n\n**阿姆达尔定律**给了很现实的结论：\n$$Speedup \\leq \\frac{1}{F + \\frac{1 - F}{N}}$$\n这里的**F可以表示代码的串行率**，**N表示核的数量。**\n\n> 可并行的代码比例很大程度上决定了你的系统计算能力。或者换句话说，串行的代码越少，在相同计算能力下的系统QPS带来的收益就越大（其实想想很容易理解）。\n\n这里贴两个引用的例子来表述阿姆达尔定律：\n\n##### 1.坐车问题：\n假设你想从望京去顺义，那么你只能坐着一辆车过去，虽然现在有十辆车，你也不能提升十倍的效率，这里F就是1，因为所有的动作都需要串行，speedup就等于1，效率没提升，虽然你有九辆车。\n##### 2.写代码问题：\n假设你现在开发一个系统，你可以把所有的任务均分下去，假设10个人帮你开发，那么F就为0，N为10，那么speedup等于10，也就是说你提升了10倍的速率。\n\n---\n\n在我们的应用场景下:\n$$mutiThreadQPS = {1s \\over CPU Time} \\times {CPU CoreNum \\times CPU Ratio}$$\n如果当你通过添加CPU Core来提高计算能力的同时（N），QPS会提升。\n\n但同时处理的请求所带来的资源竞争占比（比如上下文切换、锁竞争等）也会越来越大(F)。(**CPUcore与QPS非线性比例**)\n\n---\n\n### 5.结论\n\n如果你尝试的通过增加线程数来提高计算能力（前提是CPU利用率不满），那么当线程数达到一个峰值之后，因为线程切换以及资源竞争甚至GC Time带来的副作用会越来越大而导致整个业务的RT下降，最终QPS也会下降。\n\n所以我们希望的是在核数一定的情况下找到某个点，使系统的QPS最大，RT相对较小。\n\n所以我们需要不断的压测，调整线程池，找到这个QPS的峰值，并且使CPU的利用率达到100%,这样才是系统的最大QPS和最佳线程数。\n\n1. 最终还是需要不断的压测来调整出正确的线程数量.。\n2. 提高CPU利用率，尽可能的减少资源竞争，IO阻塞，提高代码并行率。","tags":["基础积累"]},{"title":"关于SpringMVC的工作流程问题","url":"/2017/10/11/关于SpringMVC的工作流程问题/","content":"\n首先说明一下问题，之前遇到一个需求，是在springMVC中实现controller层的参数绑定。\n参数绑定意思就是：\n\n```\n@RequestMapping(value = \"/validator/test\", method = {RequestMethod.GET})\n@ResponseBody\n@FdMethodValidate\npublic String validatorModelControl(\n        @Min(10) @RequestParam(\"ten\") Integer ten,\n        @RequestParam(\"ignore\") Integer ignore,\n        @FdValidate  TestModel testModel, FdValidResult result) {\n    if (result.hasErrors()) {\n        List<FdValidError> lists = result.getErrors();\n        for (FdValidError row : lists) {\n            row.getErrorMessage();\n            LOGGER.error(row.getErrorMessage());\n        }\n    }\n    return \"success\";\n}\n```\n\n我希望在调用该接口之前先获取参数、进行逻辑操作、最后将输出结果绑定到FdValidResult中。\n\n最先想到的就是通过拦截器的在调用方法前进行预操作，并进行参数绑定。\n\n看起来好像很简单，实际上是却是一顿操作后打出了GG。\n \n\n---\n\n为什么会没有办法进行参数绑定，我门一步一步的调试这看。\n\n首先在不知道请求参数的情况下，如果要获取传递的参数则必须要提前调用参数解析器ArgumentResolver（为什么会说提前，后面会讲），所以拦截器的工作大致是：\n\n1. 获得参数签名\n2. 找出能够解析该参数的ArgumentResolver，\n3. 调用ArgumentResolver进行参数解析，流程是：\n    1. 如果为基本类型，则是RequestParamMapMethodArgumentResolver来进行解析。这一块具体细节没有太做研究，大致是从request的请求参数名称与参数签名进行匹配，最终返回的是基本类型的值。\n    2. 如果为ModelAttribute，则调用ModelAttributeMethodProcessor来进行解析。具体细节首先调用DataBinder将参数与Model属性进行绑定，同时还会进行数据校验（另一个坑）并叫校验结果BindResult存入ModelAndViewContainer中\n    3. 如果是BindResult类型，则调用ErrorsMethodArgumentResolver进行解析，它会从ModelAndViewContainer中尝试获取该类型，如果存在则返回该对象，否则抛出异常。\n```\npublic final Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception {\n    String name = ModelFactory.getNameForParameter(parameter);\n    Object attribute = mavContainer.containsAttribute(name)?mavContainer.getModel().get(name):this.createAttribute(name, parameter, binderFactory, webRequest);\n    WebDataBinder binder = binderFactory.createBinder(webRequest, attribute, name);\n    if(binder.getTarget() != null) {\n        this.bindRequestParameters(binder, webRequest);\n        this.validateIfApplicable(binder, parameter);\n        if(binder.getBindingResult().hasErrors() && this.isBindExceptionRequired(binder, parameter)) {\n            throw new BindException(binder.getBindingResult());\n        }\n    }\n \n    Map<String, Object> bindingResultModel = binder.getBindingResult().getModel();\n    mavContainer.removeAttributes(bindingResultModel);\n    mavContainer.addAllAttributes(bindingResultModel);\n    return binder.convertIfNecessary(binder.getTarget(), parameter.getParameterType(), parameter);\n}\n```\n\n```\npublic Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception {\n    ModelMap model = mavContainer.getModel();\n    if(model.size() > 0) {\n        int lastIndex = model.size() - 1;\n        String lastKey = (String)(new ArrayList(model.keySet())).get(lastIndex);\n        if(lastKey.startsWith(BindingResult.MODEL_KEY_PREFIX)) {\n            return model.get(lastKey);\n        }\n    }\n \n    throw new IllegalStateException(\"An Errors/BindingResult argument is expected to be declared immediately after the model attribute, the @RequestBody or the @RequestPart arguments to which they apply: \" + parameter.getMethod());\n}\n```\n\n所以根据BindResult的解析逻辑，我只要将逻辑结果封装成一个DataBinder，并将其注入ModelAndViewContainer，貌似就完成了。\n\n当然没有那么简单，那么问题出现在哪里呢？\n\n从DispatchServlet开始走起：\n\n```\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {\n    HttpServletRequest processedRequest = request;\n    HandlerExecutionChain mappedHandler = null;\n    boolean multipartRequestParsed = false;\n    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n \n    try {\n        ModelAndView mv = null;\n        Exception dispatchException = null;\n \n        try {\n            processedRequest = this.checkMultipart(request);\n            multipartRequestParsed = processedRequest != request;\n            mappedHandler = this.getHandler(processedRequest);\n            if(mappedHandler == null || mappedHandler.getHandler() == null) {\n                this.noHandlerFound(processedRequest, response);\n                return;\n            }\n \n            HandlerAdapter ha = this.getHandlerAdapter(mappedHandler.getHandler());\n            String method = request.getMethod();\n            boolean isGet = \"GET\".equals(method);\n            if(isGet || \"HEAD\".equals(method)) {\n                long lastModified = ha.getLastModified(request, mappedHandler.getHandler());\n                if(this.logger.isDebugEnabled()) {\n                    this.logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified);\n                }\n \n                if((new ServletWebRequest(request, response)).checkNotModified(lastModified) && isGet) {\n                    return;\n                }\n            }\n \n            if(!mappedHandler.applyPreHandle(processedRequest, response)) {\n                return;\n            }\n \n            mv = ha.handle(processedRequest, response, mappedHandler.getHandler());\n            if(asyncManager.isConcurrentHandlingStarted()) {\n                return;\n            }\n \n            this.applyDefaultViewName(request, mv);\n            mappedHandler.applyPostHandle(processedRequest, response, mv);\n        } catch (Exception var19) {\n            dispatchException = var19;\n        }\n \n        this.processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\n    } catch (Exception var20) {\n        this.triggerAfterCompletion(processedRequest, response, mappedHandler, var20);\n    } catch (Error var21) {\n        this.triggerAfterCompletionWithError(processedRequest, response, mappedHandler, var21);\n    } finally {\n        if(asyncManager.isConcurrentHandlingStarted()) {\n            if(mappedHandler != null) {\n                mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);\n            }\n        } else if(multipartRequestParsed) {\n            this.cleanupMultipart(processedRequest);\n        }\n \n    }\n \n}\n```\n\n前面通过HandlerMapping找到对应的Handler过程省略掉不关键，关键是我们能看到HanderAdpater执行handler之前会先拦截器的执行preHandle。\n\n那这又有什么关系呢？我们想起之前在prehandle进行操作的过程，期间再参数解析ArgumentResolve的时候使用了ModelAndViewContiner这个关键的容器。\n\n那我们再看继续调试，看看预处理后的HandlerAdapter怎么做处理，继续一步一步调试，然后最终会执行RequestMappingHandlerAdapter这个实现类的这个方法：\n\n```\nprivate ModelAndView invokeHandleMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception {\n    ServletWebRequest webRequest = new ServletWebRequest(request, response);\n    WebDataBinderFactory binderFactory = this.getDataBinderFactory(handlerMethod);\n    ModelFactory modelFactory = this.getModelFactory(handlerMethod, binderFactory);\n    ServletInvocableHandlerMethod requestMappingMethod = this.createRequestMappingMethod(handlerMethod, binderFactory);\n    ModelAndViewContainer mavContainer = new ModelAndViewContainer();\n    mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request));\n    modelFactory.initModel(webRequest, mavContainer, requestMappingMethod);\n    mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect);\n    AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response);\n    asyncWebRequest.setTimeout(this.asyncRequestTimeout);\n    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n    asyncManager.setTaskExecutor(this.taskExecutor);\n    asyncManager.setAsyncWebRequest(asyncWebRequest);\n    asyncManager.registerCallableInterceptors(this.callableInterceptors);\n    asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors);\n    if(asyncManager.hasConcurrentResult()) {\n        Object result = asyncManager.getConcurrentResult();\n        mavContainer = (ModelAndViewContainer)asyncManager.getConcurrentResultContext()[0];\n        asyncManager.clearConcurrentResult();\n        if(this.logger.isDebugEnabled()) {\n            this.logger.debug(\"Found concurrent result value [\" + result + \"]\");\n        }\n \n        requestMappingMethod = requestMappingMethod.wrapConcurrentResult(result);\n    }\n \n    requestMappingMethod.invokeAndHandle(webRequest, mavContainer, new Object[0]);\n    return asyncManager.isConcurrentHandlingStarted()?null:this.getModelAndView(mavContainer, modelFactory, webRequest);\n}\n```\n\n\n看到这里就明白了，无论你在拦截器中如何定义DataBinder如何声明ModelAndViewContainer容器，在拦截器执行后执行Handler时都会被重置。这就是在拦截器不可能进行参数绑定的原因，因为拦截器的执行要先于HandlerAdapter的执行的。\n\n---\n\n最后附一张到来的SpringMVC的执行流程图，加深一下印象：\n![image](http://neoremind.com/wp-content/uploads/060828381f30e92466d592d34e086e061c95f7db.png)\n\n个人理解，欢迎讨论","tags":["java","经验总结"]},{"title":"《深入理解JVM系列》之Java内存区域与内存溢出异常（一）","url":"/2016/10/12/JVM_1_Java内存区域与内存溢出异常/","content":"\n> 内容学习自《深入理解JVM虚拟机》\n\n\n## 一.jvm的内存区域\njava虚拟机规范规定的java虚拟机内存其实就是java虚拟机运行时数据区，其架构如下：\n\n<img src=\"/imgs/jvm_1_1.png\" width=\"50%\" />\n\n其中**方法区和堆**是由所有线程共享的数据区。\n**Java虚拟机栈，本地方法栈和程序计数器**是线程隔离的数据区。\n\n### 1.程序计数器：\n是一块较小的内存空间，其作用可以看作是当前线程所执行的字节码的行号指示器，字节码解析器工作时通过改变程序计数器的值来选取下一条需要执行的字节码指令。程序的分支、循环、跳转、异常处理以及线程恢复等基础功能都是依赖程序计数器来完成。\n\nJava虚拟机的多线程是通过线程轮流切换并分配处理器执行时间片来实现，在任何一个时刻，一个处理器只会执行一条线程指令，因此，为了确保线程切换之后能恢复到正确的执行位置，每条线程都需要一个独立的程序计数器，因此程序计数器是线程私有的内存。\n\n>程序计数器是java虚拟机中唯一一个没有规定任何内存溢出OutOfMemoryError的内存区域。\n\n### 2.java虚拟机栈：\nJava虚拟机栈也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是java方法执行的内存模型：每个方法被执行时都会同时创建一个栈帧用于存放**局部变量表、操作数栈、动态连接和方法出口等**信息。每个方法被调用直至执行完成过程，就对应着一个栈帧在虚拟机中从入栈到出栈的过程。\n\nJava虚拟机栈的局部变量表存放了编译器可知的**8种java基本类型数据、对象引用(注意不是对象实例本身)、方法返回地址returnAddress**。\nJava虚拟机栈的局部变量表空间单位是槽(Slot)(这部分后面会讲到)，其中64位长度的double和long类型会占用两个slot，其余的数据类型只占用一个slot。局部变量表所需内存空间在编译期间完成分配，当进入一个方法时，该方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。\n\n> Java虚拟机栈有两种异常状况：如果线程请求的栈深度大于虚拟机所允许的最大深度时，抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，当扩展时无法申请到足够内存时会抛出OutOfMemoryError异常。\n\n### 3.本地方法栈：\n本地方法栈与java虚拟机栈作用非常类似，其区别是：**java虚拟机栈是为虚拟机执行java方法服务，而本地方法栈是为虚拟机调用的操作系统本地方法服务**。\n\nJava虚拟机规范没有对本地方法栈的实现和数据结构做强制规定，Sun HotSpot虚拟机直接把java虚拟机栈和本地方法栈合二为一。\n\n> 与java虚拟机栈类似，本地方法栈也会抛出StackOverflowError异常和OutOfMemoryError异常。\n\n### 4.堆：\n堆是java虚拟机所管理的内存区域中最大一块，java堆是被所有线程所共享的一块内存区域，在java虚拟机启动时创建，堆内存的唯一目的就是存放对象实例。几乎所有的对象实例都是在堆分配内存。\n\nJava堆是垃圾收集器管理的主要区域，从垃圾回收的角度看，由于现在的垃圾收集器基本都采用的是分代收集算法，因此java堆还可以初步细分为新生代和年老代。\n\nJava虚拟机规范规定，堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。在实现上即可以是固定大小的，也可以是可动态扩展的。如果在堆中没有内存完成实例分配，并且堆大小也无法在扩展时，将会抛出OutOfMemoryError异常。\n\n### 5.方法区：\n方法区与堆一样，是被各个线程共享的内存区域，它用于存储已被虚拟机加载的**类信息、常量、静态变量、即时编译后的代码等**数据。虽然java虚拟机规范把方法区描述为堆的一个逻辑部分，但是方法区却有一个别名叫Non-Heap(非堆)。\n\nSun HotSpot虚拟机把方法区叫永久代(Permanent Generation)(JDK1.7以后已经把原本放在永久代的字符串常量池移出)。\n\n**常量池**：方法区中最重要的部分是运行时常量池。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面变量、符号引用、直接引用等，这些内容将在类加载后存放到方法区的运行时常量池中，另外在运行期间也可以将新的常量存放到常量池中，如String的intern()方法。\n\n> 方法区和运行时常量池在无法满足内存分配时，也会抛出OutOfMemoryError异常。\n\n> PS:\n> \n> **直接引用**:\n> \n> 对于指向“类型”【Class对象】、类变量、类方法的直接引用可能是指向方法区的本地指针。指向实例变量、实例方法的直接引用都是偏移量。实例变量的直接引用可能是从对象的映像开始算起到这个实例变量位置的偏移量。实例方法的直接引用可能是方法表的偏移量。\n\n> **符号引用：**\n> \n> 符号引用是一个字符串，它给出了被引用的内容的名字并且可能会包含一些其他关于这个被引用项的信息——这些信息必须足以唯一的识别一个类、字段、方法。这样，对于其他类的符号引用必须给出类的全名。对于其他类的字段，必须给出类名、字段名以及字段描述符。对于其他类的方法的引用必须给出类名、方法名以及方法的描述符。\n\n\n### 6.直接内存：\n直接内存并不是java虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的内存区域，但是在java开发中还是会使用到。\n\nJDK1.4中新引入的NIO(new I/O)，引入了一种基于通道(Channel)和缓冲区(Buffer)的I/O方式，可以使用操作系统本地方法库直接分配堆外内存，然后通过一个存储在java堆里面的DirectByteBuffer对象作为堆外直接内存的引用进行操作，避免了java堆内存和本地直接内存间的数据拷贝，可以显著提高性能。\n\n虽然直接内存并不直接收到java虚拟机内存影响，但是如果java虚拟机各个内存区域总和大于物理内存限制，从而导致直接内存不足，动态扩展时也会抛出OutOfMemoryError异常。\n\n\njava虚拟机内存结构中的程序计数器、虚拟机栈和本地方法栈这三个区域随线程创建而生，随线程销毁而灭，因此这三个区域的内存分配和回收是确定的，java垃圾收集器重点关注的是java虚拟机的堆内存和方法区内存。\n\n\n\n> PS: 对象的创建过程（关键词：指针碰撞、空闲列表、TLAB本地线程分配缓冲、对象头、偏向锁）：\n> \n>  1. 程序执行到new 语句时，JVM首先去运行时常量池中查询是否有那个类的符号引用，并检查是否被加载、解析、初始化。\n>  2. 若没有，则进行类加载。（加载的类信息、常量池、静态变量等会被加载到方法区）\n>  3. 给对象分配堆内存空间（获取对象长度、决定哪种线程安全策略（如CAS（compareAndSet）失败重试或者分配动作交给TLAB）、使用指针碰撞或者是空闲列表的分配方式）。\n>  4. 将对象初始化为零值（若需要）\n>  5. 设置对象的对象头信息以及偏向锁\n>  6. 进行构造函数初始化\n\n> PS2: 对象的内存布局（三块：对象头、实例数据、对齐填充（以及可能的数组长度））：\n\n>  1. 执行的方法会在虚拟机栈中创建一个编译期可知大小的栈帧，存放各种基本数据类型和对象引用（方法局部变量）\n>  2. 通过对象的引用（方式有使用句柄、直接指针）去操作堆上的具体对象，如类的属性（包含基本类型）、方法。\n    \n## 二.内存溢出异常\n\n通过简单的小例子程序，演示java虚拟机各部分内存溢出情况：\n\n### 1.java堆溢出：\nJava堆用于存储实例对象，只要不断创建对象，并且保证GC Roots到对象之间有引用的可达，避免垃圾收集器回收实例对象，就会在对象数量达到堆最大容量时产生OutOfMemoryError异常。\n\n想要方便快速地产生堆溢出，要使用如下java虚拟机参数：-Xms10m(最小堆内存为10MB)，-Xmx10m(最大堆内存为10MB，最小堆内存和最大堆内存相同是为了避免堆动态扩展)，-XX:+HeapDumpOnOutOfMemoryError可以让java虚拟机在出现内存溢出时产生当前堆内存快照以便进行异常分析。\n\n例子代码如下：\n\n```\npublic class HeapOOM{  \n    static class OOMObject{ }\n}  \npublic static void main(String[] args){  \n    List<OOMObject> list = new ArrayList<OOMObject>();  \n    while(true){  \n    list.add(new OOMObject());  \n\t}  \n}  \n```\n\n运行一段时间就会发现产生OutOfMemoryError异常，并且产生了堆内存异常dump文件。\n\n### 3.java虚拟机栈和本地方法栈溢出：\n由于Sun的HotSpot虚拟机不区分java虚拟机栈和本地方法栈，因此对于HotSpot虚拟机来说-Xoss参数(设置本地方法栈大小)虽然存在，但是实际上是无效的，栈容量只能由-Xss参数设定。\n\n由于Java虚拟机栈会出现StackOverflowError和OutOfMemoryError两种异常，所以分别使用两个例子演示这两种情况：\n\n#### a.java虚拟机栈深度溢出：\n\n单线程的环境下，无论是由于栈帧太大，还是虚拟机栈容量太小，当内存无法再分配的时候，虚拟机总抛出StackOverflowError异常。使用-Xss128k将java虚拟机栈大小设置为128kb，例子代码如下：\n\n```\npublic class JavaVMStackOF{  \n    private int stackLength = 1;  \n    public void stackLeak(){  \n        statckLength++;  \n        stackLeak();  \n    }\n}  \npublic static void main(String[] args){  \n    JavaVMStackOF oom = new JavaVMStackOF();  \noom.stackLeak();  \n}  \n```\n \n运行一段时间后，产生StackOverflowError异常。Java虚拟机栈溢出一般会产生在方法递归调用过多而java虚拟机栈内存不够的情况下。\n\n#### b.java虚拟机栈内存溢出：\n多线程环境下，能够创建的线程最大内存=物理内存-最大堆内存-最大方法区内存，在java虚拟机栈内存一定的情况下，单个线程占用的内存越大，所能创建的线程数目越小，所以在多线程条件下很容易产生java虚拟机栈内存溢出的异常。\n使用-Xss2m参数设置java虚拟机栈内存大小为2MB，例子代码如下：\n\n```\npublic class JavaVMStackOOM{  \n    private void dontStop(){  \n\t    while(true){  \n\t\t}  \n\t}  \n}\npublic void stackLeakByThread(){  \n    while(true){  \n        Thread t = new Thread(new Runnable(){  \n\t\t    public void run(){  \n\t\t    dontStop();  \n\t\t\t}  \n\t\t});  \n\tt.start();\n\t}  \n}  \n \npublic static void main(String[] args){  \n    JavaVMStackOOM oom = new JavaVMStackOOM();  \n    oom.stackLeakByThread();\n}  \n```\n\n运行一段时间之后，java虚拟机栈就会因为内存太小无法创建线程而产生OutOfMemoryError。\n\n### 3.运行时常量池溢出（这里的例子在JDK1.7之后已经不会产生异常（字符串常量池已经移出永久代））\n\n运行时常量池属于方法区的一部分，可以使用-XX:PermSize=10m和-XX:MaxPermSize=10m将永久代最大内存和最小内存设置为10MB大小，并且由于永久代最大内存和最小内存大小相同，因此无法扩展。\n\nString的intern()方法用于检查常量池中如果有等于此String对象的字符串存在，则直接返回常量池中的字符串对象，否则，将此String对象所包含的字符串添加到运行时常量池中，并返回此String对象的引用。因此String的intern()方法特别适合演示运行时常量池溢出，例子代码如下：\n\n```\npublic class RuntimeConstantPoolOOM{  \n    public static void main(String[] args){  \nList<String> list = new ArrayList<String>();  \n        int i = 0;  \n        while(true){  \n        \tlist.add(String.valueOf(i++).intern());  \n\t\t}  \n\t}  \n}  \n```\n\n运行一段时间，永久代内存不够，运行时常量池因无法再添加常量而产生OutOfMemoryError。\n\n### 4.方法区溢出：\n运行时常量池是方法区的一部分，他们都属于HotSpot虚拟机中的永久代内存区域。方法区用于存放Class的相关信息，Java的反射和动态代理可以动态产生Class，另外第三方的CGLIB可以直接操作字节码，也可以动态产生Class，实验通过CGLIB来演示，同样使用-XX:PermSize=10m和-XX:MaxPermSize=10m将永久代最大内存和最小内存设置为10MB大小，并且由于永久代最大内存和最小内存大小相同，因此无法扩展。例子代码如下：\n\n```\npublic class JavaMethodAreaOOM{  \n    public static void main(String[] args){  \n\t    while(true){  \n\t\t    Enhancer enhancer = new Enhancer();  \n\t\t    enhancer.setSuperClass(OOMObject.class);  \n\t\t    enhancer.setUseCache(false);  \n\t\t    enhancer.setCallback(new MethodInterceptor(){  \n\t\t\t    public Object intercept(Object obj, Method method, Object[] args,   \n\t\t\t\t                      MethodProxy proxy)throws Throwable{  \n\t\t\t    \treturn proxy.invokeSuper(obj, args);  \n\t\t\t\t}  \n\t\t\t});  \n\t\t\tenhancer.create();  \n\t\t}  \n\t} \n} \nclass OOMObject{  \n}     \n```\n\n运行一段时间之后，永久代内存不够，方法区无法再存放CGLIB创建处理的Class信息，产生方法区OutOfMemoryError。\n\n### 5.本机直接内存溢出：\nJava虚拟机可以通过参数-XX:MaxDirectMemorySize设定本机直接内存可用大小，如果不指定，则默认与java堆内存大小相同。JDK中可以通过反射获取Unsafe类(Unsafe的getUnsafe()方法只有启动类加载器Bootstrap才能返回实例)直接操作本机直接内存。通过使用-XX:MaxDirectMemorySize=10M，限制最大可使用的本机直接内存大小为10MB，例子代码如下：\n\n```\npublic class DirectMemoryOOM{  \n    private static final int _1MB = 1024* 1024 * 1024;  \n    publc static void main(String[] args) throws Exception{  \n        Field unsafeField = Unsafe.class.getDeclaredFields()[0];  \n        unsafeField.setAccessible(true);  \n        Unsafe unsafe = (Unsafe) unsafeField.get(null);  \n        while(true){  \n            //unsafe直接想操作系统申请内存  \n\t\t    unsafe.allocateMemory(_1MB);  \n\t\t}  \n\t}  \n}  \n```\n\n当运行一段时间之后，10MB的本机直接内存被分配光，无法在进行直接内存分配时，产生OutOfMemoryError。\n\n> PS:由DirectMemory导致内存溢出，一个明显的特征是在HeapDump文件中不会看见明显的异常，如果发现OOM之后Dump文件很小，而程序中又直接或间接只用了NIO，那可以考虑下这方面原因。\n> \n> PS2：DirectMemory不能像minor和old那样空间不足了就通知收集器进行垃圾回收，它只能等待老年代满了后Full GC,然后顺便帮他清理掉内存的废弃对象。否则只能等到抛出内存异常时，先catch掉，再在catch块里面System.gc()。如果jvm不听（如开启了-XX:+DisableExplicitGC开关），那没办法了。\n","tags":["基础积累","深入理解JVM"]}]